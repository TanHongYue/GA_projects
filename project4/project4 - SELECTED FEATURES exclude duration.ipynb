{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to dataset: \n",
    "http://archive.ics.uci.edu/ml/datasets/Bank+Marketing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics attribute: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring parameter in cross_val_score: http://scikit-learn.org/stable/modules/model_evaluation.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 70) #https://stackoverflow.com/questions/11707586/python-pandas-how-to-widen-output-display-to-see-more-columns\n",
    "pd.set_option('display.max_rows', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = pd.read_csv('bank-additional-full.csv')\n",
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#41,188 rows and 21 columns\n",
    "clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      "age               41188 non-null int64\n",
      "job               41188 non-null object\n",
      "marital           41188 non-null object\n",
      "education         41188 non-null object\n",
      "default           41188 non-null object\n",
      "housing           41188 non-null object\n",
      "loan              41188 non-null object\n",
      "contact           41188 non-null object\n",
      "month             41188 non-null object\n",
      "day_of_week       41188 non-null object\n",
      "duration          41188 non-null int64\n",
      "campaign          41188 non-null int64\n",
      "pdays             41188 non-null int64\n",
      "previous          41188 non-null int64\n",
      "poutcome          41188 non-null object\n",
      "emp.var.rate      41188 non-null float64\n",
      "cons.price.idx    41188 non-null float64\n",
      "cons.conf.idx     41188 non-null float64\n",
      "euribor3m         41188 non-null float64\n",
      "nr.employed       41188 non-null float64\n",
      "y                 41188 non-null object\n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "duration          0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "y                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.isnull().sum() #no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "31    1947\n",
      "32    1846\n",
      "33    1833\n",
      "36    1780\n",
      "35    1759\n",
      "34    1745\n",
      "30    1714\n",
      "37    1475\n",
      "29    1453\n",
      "39    1432\n",
      "38    1407\n",
      "41    1278\n",
      "      ... \n",
      "85      15\n",
      "79      14\n",
      "86       8\n",
      "84       7\n",
      "17       5\n",
      "92       4\n",
      "98       2\n",
      "89       2\n",
      "91       2\n",
      "87       1\n",
      "94       1\n",
      "95       1\n",
      "Name: age, Length: 78, dtype: int64\n",
      "job\n",
      "admin.           10422\n",
      "blue-collar       9254\n",
      "technician        6743\n",
      "services          3969\n",
      "management        2924\n",
      "retired           1720\n",
      "entrepreneur      1456\n",
      "self-employed     1421\n",
      "housemaid         1060\n",
      "unemployed        1014\n",
      "student            875\n",
      "unknown            330\n",
      "Name: job, dtype: int64\n",
      "marital\n",
      "married     24928\n",
      "single      11568\n",
      "divorced     4612\n",
      "unknown        80\n",
      "Name: marital, dtype: int64\n",
      "education\n",
      "university.degree      12168\n",
      "high.school             9515\n",
      "basic.9y                6045\n",
      "professional.course     5243\n",
      "basic.4y                4176\n",
      "basic.6y                2292\n",
      "unknown                 1731\n",
      "illiterate                18\n",
      "Name: education, dtype: int64\n",
      "default\n",
      "no         32588\n",
      "unknown     8597\n",
      "yes            3\n",
      "Name: default, dtype: int64\n",
      "housing\n",
      "yes        21576\n",
      "no         18622\n",
      "unknown      990\n",
      "Name: housing, dtype: int64\n",
      "loan\n",
      "no         33950\n",
      "yes         6248\n",
      "unknown      990\n",
      "Name: loan, dtype: int64\n",
      "contact\n",
      "cellular     26144\n",
      "telephone    15044\n",
      "Name: contact, dtype: int64\n",
      "month\n",
      "may    13769\n",
      "jul     7174\n",
      "aug     6178\n",
      "jun     5318\n",
      "nov     4101\n",
      "apr     2632\n",
      "oct      718\n",
      "sep      570\n",
      "mar      546\n",
      "dec      182\n",
      "Name: month, dtype: int64\n",
      "day_of_week\n",
      "thu    8623\n",
      "mon    8514\n",
      "wed    8134\n",
      "tue    8090\n",
      "fri    7827\n",
      "Name: day_of_week, dtype: int64\n",
      "duration\n",
      "85      170\n",
      "90      170\n",
      "136     168\n",
      "73      167\n",
      "124     164\n",
      "87      162\n",
      "72      161\n",
      "104     161\n",
      "111     160\n",
      "106     159\n",
      "109     158\n",
      "97      158\n",
      "       ... \n",
      "1575      1\n",
      "1767      1\n",
      "1236      1\n",
      "3253      1\n",
      "2089      1\n",
      "1204      1\n",
      "1140      1\n",
      "1108      1\n",
      "980       1\n",
      "4918      1\n",
      "2453      1\n",
      "2015      1\n",
      "Name: duration, Length: 1544, dtype: int64\n",
      "campaign\n",
      "1     17642\n",
      "2     10570\n",
      "3      5341\n",
      "4      2651\n",
      "5      1599\n",
      "6       979\n",
      "7       629\n",
      "8       400\n",
      "9       283\n",
      "10      225\n",
      "11      177\n",
      "12      125\n",
      "      ...  \n",
      "31        7\n",
      "35        5\n",
      "33        4\n",
      "32        4\n",
      "34        3\n",
      "40        2\n",
      "42        2\n",
      "43        2\n",
      "37        1\n",
      "39        1\n",
      "41        1\n",
      "56        1\n",
      "Name: campaign, Length: 42, dtype: int64\n",
      "pdays\n",
      "999    39673\n",
      "3        439\n",
      "6        412\n",
      "4        118\n",
      "9         64\n",
      "2         61\n",
      "7         60\n",
      "12        58\n",
      "10        52\n",
      "5         46\n",
      "13        36\n",
      "11        28\n",
      "       ...  \n",
      "8         18\n",
      "0         15\n",
      "16        11\n",
      "17         8\n",
      "18         7\n",
      "19         3\n",
      "22         3\n",
      "21         2\n",
      "26         1\n",
      "20         1\n",
      "25         1\n",
      "27         1\n",
      "Name: pdays, Length: 27, dtype: int64\n",
      "previous\n",
      "0    35563\n",
      "1     4561\n",
      "2      754\n",
      "3      216\n",
      "4       70\n",
      "5       18\n",
      "6        5\n",
      "7        1\n",
      "Name: previous, dtype: int64\n",
      "poutcome\n",
      "nonexistent    35563\n",
      "failure         4252\n",
      "success         1373\n",
      "Name: poutcome, dtype: int64\n",
      "emp.var.rate\n",
      " 1.4    16234\n",
      "-1.8     9184\n",
      " 1.1     7763\n",
      "-0.1     3683\n",
      "-2.9     1663\n",
      "-3.4     1071\n",
      "-1.7      773\n",
      "-1.1      635\n",
      "-3.0      172\n",
      "-0.2       10\n",
      "Name: emp.var.rate, dtype: int64\n",
      "cons.price.idx\n",
      "93.994    7763\n",
      "93.918    6685\n",
      "92.893    5794\n",
      "93.444    5175\n",
      "94.465    4374\n",
      "93.200    3616\n",
      "93.075    2458\n",
      "92.201     770\n",
      "92.963     715\n",
      "92.431     447\n",
      "92.649     357\n",
      "94.215     311\n",
      "          ... \n",
      "92.379     267\n",
      "93.369     264\n",
      "94.027     233\n",
      "94.055     229\n",
      "93.876     212\n",
      "94.601     204\n",
      "92.469     178\n",
      "93.749     174\n",
      "92.713     172\n",
      "94.767     128\n",
      "93.798      67\n",
      "92.756      10\n",
      "Name: cons.price.idx, Length: 26, dtype: int64\n",
      "cons.conf.idx\n",
      "-36.4    7763\n",
      "-42.7    6685\n",
      "-46.2    5794\n",
      "-36.1    5175\n",
      "-41.8    4374\n",
      "-42.0    3616\n",
      "-47.1    2458\n",
      "-31.4     770\n",
      "-40.8     715\n",
      "-26.9     447\n",
      "-30.1     357\n",
      "-40.3     311\n",
      "         ... \n",
      "-29.8     267\n",
      "-34.8     264\n",
      "-38.3     233\n",
      "-39.8     229\n",
      "-40.0     212\n",
      "-49.5     204\n",
      "-33.6     178\n",
      "-34.6     174\n",
      "-33.0     172\n",
      "-50.8     128\n",
      "-40.4      67\n",
      "-45.9      10\n",
      "Name: cons.conf.idx, Length: 26, dtype: int64\n",
      "euribor3m\n",
      "4.857    2868\n",
      "4.962    2613\n",
      "4.963    2487\n",
      "4.961    1902\n",
      "4.856    1210\n",
      "4.964    1175\n",
      "1.405    1169\n",
      "4.965    1071\n",
      "4.864    1044\n",
      "4.960    1013\n",
      "4.968     992\n",
      "4.959     895\n",
      "         ... \n",
      "3.901       1\n",
      "1.574       1\n",
      "3.488       1\n",
      "3.853       1\n",
      "3.669       1\n",
      "3.053       1\n",
      "3.816       1\n",
      "1.045       1\n",
      "0.956       1\n",
      "0.933       1\n",
      "3.282       1\n",
      "0.996       1\n",
      "Name: euribor3m, Length: 316, dtype: int64\n",
      "nr.employed\n",
      "5228.1    16234\n",
      "5099.1     8534\n",
      "5191.0     7763\n",
      "5195.8     3683\n",
      "5076.2     1663\n",
      "5017.5     1071\n",
      "4991.6      773\n",
      "5008.7      650\n",
      "4963.6      635\n",
      "5023.5      172\n",
      "5176.3       10\n",
      "Name: nr.employed, dtype: int64\n",
      "y\n",
      "no     36548\n",
      "yes     4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in clients.columns.tolist():  #Skim through the variables\n",
    "    print(i)\n",
    "    print(clients[i].value_counts())\n",
    "\n",
    "#clients.columns[0]\n",
    "#clients.job.value_counts()\n",
    "#clients[job].value_counts()\n",
    "#clients.groupby('job').job.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_duplicate = clients.duplicated(keep=False)\n",
    "#clients[is_duplicate] --- to check if indeed the 12 rows are dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.drop_duplicates(keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.reset_index(drop=True, inplace=True) #reset index after dropping dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 21)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = clients.iloc[:,:-1].drop(columns=['education'])\n",
    "edu = clients['education']\n",
    "target = clients.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital  default housing loan    contact month day_of_week  \\\n",
       "0   56  housemaid  married       no      no   no  telephone   may         mon   \n",
       "1   57   services  married  unknown      no   no  telephone   may         mon   \n",
       "2   37   services  married       no     yes   no  telephone   may         mon   \n",
       "3   40     admin.  married       no      no   no  telephone   may         mon   \n",
       "4   56   services  married       no      no  yes  telephone   may         mon   \n",
       "\n",
       "   duration  campaign  pdays  previous     poutcome  emp.var.rate  \\\n",
       "0       261         1    999         0  nonexistent           1.1   \n",
       "1       149         1    999         0  nonexistent           1.1   \n",
       "2       226         1    999         0  nonexistent           1.1   \n",
       "3       151         1    999         0  nonexistent           1.1   \n",
       "4       307         1    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0          93.994          -36.4      4.857       5191.0  \n",
       "1          93.994          -36.4      4.857       5191.0  \n",
       "2          93.994          -36.4      4.857       5191.0  \n",
       "3          93.994          -36.4      4.857       5191.0  \n",
       "4          93.994          -36.4      4.857       5191.0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    no\n",
       "1    no\n",
       "2    no\n",
       "3    no\n",
       "4    no\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0   56       261         1    999         0           1.1          93.994   \n",
       "1   57       149         1    999         0           1.1          93.994   \n",
       "2   37       226         1    999         0           1.1          93.994   \n",
       "3   40       151         1    999         0           1.1          93.994   \n",
       "4   56       307         1    999         0           1.1          93.994   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  job_admin.  job_blue-collar  \\\n",
       "0          -36.4      4.857       5191.0           0                0   \n",
       "1          -36.4      4.857       5191.0           0                0   \n",
       "2          -36.4      4.857       5191.0           0                0   \n",
       "3          -36.4      4.857       5191.0           1                0   \n",
       "4          -36.4      4.857       5191.0           0                0   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n",
       "0                 0              1               0            0   \n",
       "1                 0              0               0            0   \n",
       "2                 0              0               0            0   \n",
       "3                 0              0               0            0   \n",
       "4                 0              0               0            0   \n",
       "\n",
       "   job_self-employed  job_services  job_student  job_technician  \\\n",
       "0                  0             0            0               0   \n",
       "1                  0             1            0               0   \n",
       "2                  0             1            0               0   \n",
       "3                  0             0            0               0   \n",
       "4                  0             1            0               0   \n",
       "\n",
       "   job_unemployed  job_unknown  marital_divorced  marital_married  \\\n",
       "0               0            0                 0                1   \n",
       "1               0            0                 0                1   \n",
       "2               0            0                 0                1   \n",
       "3               0            0                 0                1   \n",
       "4               0            0                 0                1   \n",
       "\n",
       "   marital_single  marital_unknown  default_no  default_unknown  default_yes  \\\n",
       "0               0                0           1                0            0   \n",
       "1               0                0           0                1            0   \n",
       "2               0                0           1                0            0   \n",
       "3               0                0           1                0            0   \n",
       "4               0                0           1                0            0   \n",
       "\n",
       "   housing_no  housing_unknown  housing_yes  loan_no  loan_unknown  loan_yes  \\\n",
       "0           1                0            0        1             0         0   \n",
       "1           1                0            0        1             0         0   \n",
       "2           0                0            1        1             0         0   \n",
       "3           1                0            0        1             0         0   \n",
       "4           1                0            0        0             0         1   \n",
       "\n",
       "   contact_cellular  contact_telephone  month_apr  month_aug  month_dec  \\\n",
       "0                 0                  1          0          0          0   \n",
       "1                 0                  1          0          0          0   \n",
       "2                 0                  1          0          0          0   \n",
       "3                 0                  1          0          0          0   \n",
       "4                 0                  1          0          0          0   \n",
       "\n",
       "   month_jul  month_jun  month_mar  month_may  month_nov  month_oct  \\\n",
       "0          0          0          0          1          0          0   \n",
       "1          0          0          0          1          0          0   \n",
       "2          0          0          0          1          0          0   \n",
       "3          0          0          0          1          0          0   \n",
       "4          0          0          0          1          0          0   \n",
       "\n",
       "   month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0          0                0                1                0   \n",
       "1          0                0                1                0   \n",
       "2          0                0                1                0   \n",
       "3          0                0                1                0   \n",
       "4          0                0                1                0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  poutcome_failure  poutcome_nonexistent  \\\n",
       "0                0                0                 0                     1   \n",
       "1                0                0                 0                     1   \n",
       "2                0                0                 0                     1   \n",
       "3                0                0                 0                     1   \n",
       "4                0                0                 0                     1   \n",
       "\n",
       "   poutcome_success  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(features).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dummy = pd.get_dummies(features).drop(columns=['job_unknown', 'marital_unknown', 'default_unknown', \n",
    "                                                        'housing_unknown', 'loan_unknown', 'contact_telephone', \n",
    "                                                        'month_apr', 'day_of_week_mon', 'poutcome_nonexistent'])\n",
    "#k-level of cat variables are represented by (k-1) dummy variable in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0   56       261         1    999         0           1.1          93.994   \n",
       "1   57       149         1    999         0           1.1          93.994   \n",
       "2   37       226         1    999         0           1.1          93.994   \n",
       "3   40       151         1    999         0           1.1          93.994   \n",
       "4   56       307         1    999         0           1.1          93.994   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  job_admin.  job_blue-collar  \\\n",
       "0          -36.4      4.857       5191.0           0                0   \n",
       "1          -36.4      4.857       5191.0           0                0   \n",
       "2          -36.4      4.857       5191.0           0                0   \n",
       "3          -36.4      4.857       5191.0           1                0   \n",
       "4          -36.4      4.857       5191.0           0                0   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n",
       "0                 0              1               0            0   \n",
       "1                 0              0               0            0   \n",
       "2                 0              0               0            0   \n",
       "3                 0              0               0            0   \n",
       "4                 0              0               0            0   \n",
       "\n",
       "   job_self-employed  job_services  job_student  job_technician  \\\n",
       "0                  0             0            0               0   \n",
       "1                  0             1            0               0   \n",
       "2                  0             1            0               0   \n",
       "3                  0             0            0               0   \n",
       "4                  0             1            0               0   \n",
       "\n",
       "   job_unemployed  marital_divorced  marital_married  marital_single  \\\n",
       "0               0                 0                1               0   \n",
       "1               0                 0                1               0   \n",
       "2               0                 0                1               0   \n",
       "3               0                 0                1               0   \n",
       "4               0                 0                1               0   \n",
       "\n",
       "   default_no  default_yes  housing_no  housing_yes  loan_no  loan_yes  \\\n",
       "0           1            0           1            0        1         0   \n",
       "1           0            0           1            0        1         0   \n",
       "2           1            0           0            1        1         0   \n",
       "3           1            0           1            0        1         0   \n",
       "4           1            0           1            0        0         1   \n",
       "\n",
       "   contact_cellular  month_aug  month_dec  month_jul  month_jun  month_mar  \\\n",
       "0                 0          0          0          0          0          0   \n",
       "1                 0          0          0          0          0          0   \n",
       "2                 0          0          0          0          0          0   \n",
       "3                 0          0          0          0          0          0   \n",
       "4                 0          0          0          0          0          0   \n",
       "\n",
       "   month_may  month_nov  month_oct  month_sep  day_of_week_fri  \\\n",
       "0          1          0          0          0                0   \n",
       "1          1          0          0          0                0   \n",
       "2          1          0          0          0                0   \n",
       "3          1          0          0          0                0   \n",
       "4          1          0          0          0                0   \n",
       "\n",
       "   day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "0                0                0                0                 0   \n",
       "1                0                0                0                 0   \n",
       "2                0                0                0                 0   \n",
       "3                0                0                0                 0   \n",
       "4                0                0                0                 0   \n",
       "\n",
       "   poutcome_success  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#education variable is ordinal, therefore manual mapping is done here.\n",
    "edu_mapping={'unknown':0, 'illiterate':1, 'basic.4y':2, 'basic.6y':3, 'basic.9y':4, 'high.school':5, 'professional.course':6, \n",
    "            'university.degree':7}\n",
    "edu_LE = np.array(edu.map(edu_mapping))\n",
    "edu_ordinal=pd.Series(edu_LE)\n",
    "edu_ordinal.name='edu_ordinal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_LE = le.fit_transform(target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coded=pd.Series(y_LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 46)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_ordinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_coded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_coded.name='y_coded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_all = pd.concat([features_dummy, edu_ordinal, y_coded], axis=1) #combine all variables tog after necc. processing\n",
    "\n",
    "#interim = pd.merge(features_dummy, pd.DataFrame(edu_ordinal), left_index=True, right_index=True)\n",
    "#clients_all = pd.merge(interim, pd.DataFrame(y_coded),left_index=True, right_index=True)\n",
    "#clients_all = pd.concat([features_dummy, edu_ordinal, y_coded], axis=1, join_axes=[features_dummy.index])\n",
    "#interim1 = pd.concat((features_dummy, edu_ordinal), axis=1)\n",
    "#clients_all = pd.concat((interim1,y_coded), axis=1)\n",
    "#interim1 = features_dummy.join(edu_ordinal)\n",
    "#clients_all = interim1.join(y_coded)\n",
    "#clients_all = pd.concat([features_dummy, edu_ordinal, y_coded], axis=1, join_axes=[features_dummy.index])\n",
    "#https://pandas.pydata.org/pandas-docs/version/0.20/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>edu_ordinal</th>\n",
       "      <th>y_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41171</th>\n",
       "      <td>73</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41172</th>\n",
       "      <td>46</td>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41173</th>\n",
       "      <td>56</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41174</th>\n",
       "      <td>44</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41175</th>\n",
       "      <td>74</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  duration  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "41171   73       334         1    999         0          -1.1          94.767   \n",
       "41172   46       383         1    999         0          -1.1          94.767   \n",
       "41173   56       189         2    999         0          -1.1          94.767   \n",
       "41174   44       442         1    999         0          -1.1          94.767   \n",
       "41175   74       239         3    999         1          -1.1          94.767   \n",
       "\n",
       "       cons.conf.idx  euribor3m  nr.employed  job_admin.  job_blue-collar  \\\n",
       "41171          -50.8      1.028       4963.6           0                0   \n",
       "41172          -50.8      1.028       4963.6           0                1   \n",
       "41173          -50.8      1.028       4963.6           0                0   \n",
       "41174          -50.8      1.028       4963.6           0                0   \n",
       "41175          -50.8      1.028       4963.6           0                0   \n",
       "\n",
       "       job_entrepreneur  job_housemaid  job_management  job_retired  \\\n",
       "41171                 0              0               0            1   \n",
       "41172                 0              0               0            0   \n",
       "41173                 0              0               0            1   \n",
       "41174                 0              0               0            0   \n",
       "41175                 0              0               0            1   \n",
       "\n",
       "       job_self-employed  job_services  job_student  job_technician  \\\n",
       "41171                  0             0            0               0   \n",
       "41172                  0             0            0               0   \n",
       "41173                  0             0            0               0   \n",
       "41174                  0             0            0               1   \n",
       "41175                  0             0            0               0   \n",
       "\n",
       "       job_unemployed  marital_divorced  marital_married  marital_single  \\\n",
       "41171               0                 0                1               0   \n",
       "41172               0                 0                1               0   \n",
       "41173               0                 0                1               0   \n",
       "41174               0                 0                1               0   \n",
       "41175               0                 0                1               0   \n",
       "\n",
       "       default_no  default_yes  housing_no  housing_yes  loan_no  loan_yes  \\\n",
       "41171           1            0           0            1        1         0   \n",
       "41172           1            0           1            0        1         0   \n",
       "41173           1            0           0            1        1         0   \n",
       "41174           1            0           1            0        1         0   \n",
       "41175           1            0           0            1        1         0   \n",
       "\n",
       "       contact_cellular  month_aug  month_dec  month_jul  month_jun  \\\n",
       "41171                 1          0          0          0          0   \n",
       "41172                 1          0          0          0          0   \n",
       "41173                 1          0          0          0          0   \n",
       "41174                 1          0          0          0          0   \n",
       "41175                 1          0          0          0          0   \n",
       "\n",
       "       month_mar  month_may  month_nov  month_oct  month_sep  day_of_week_fri  \\\n",
       "41171          0          0          1          0          0                1   \n",
       "41172          0          0          1          0          0                1   \n",
       "41173          0          0          1          0          0                1   \n",
       "41174          0          0          1          0          0                1   \n",
       "41175          0          0          1          0          0                1   \n",
       "\n",
       "       day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "41171                0                0                0                 0   \n",
       "41172                0                0                0                 0   \n",
       "41173                0                0                0                 0   \n",
       "41174                0                0                0                 0   \n",
       "41175                0                0                0                 1   \n",
       "\n",
       "       poutcome_success  edu_ordinal  y_coded  \n",
       "41171                 0            6        1  \n",
       "41172                 0            6        0  \n",
       "41173                 0            7        0  \n",
       "41174                 0            6        1  \n",
       "41175                 0            6        0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_all.tail()\n",
    "#clients_all.to_csv('file.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 48)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36537\n",
       "1     4639\n",
       "Name: y_coded, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_all.y_coded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #normalise all variables in clients_all dataset into (0,1) scale\n",
    "mms = MinMaxScaler()\n",
    "clients_all_norm = mms.fit_transform(clients_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_all_norm = pd.DataFrame(clients_all_norm, columns = clients_all.columns) \n",
    "\n",
    "#converting normalised array into a dataframe and assigning column names to it\n",
    "#https://stackoverflow.com/questions/29586323/how-to-retain-column-headers-of-data-frame-after-pre-processing-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>edu_ordinal</th>\n",
       "      <th>y_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "1  0.493827       0.0    1.0       0.0        0.9375        0.698753   \n",
       "2  0.246914       0.0    1.0       0.0        0.9375        0.698753   \n",
       "3  0.283951       0.0    1.0       0.0        0.9375        0.698753   \n",
       "4  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  job_admin.  job_blue-collar  \\\n",
       "0        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "1        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "2        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "3        0.60251   0.957379     0.859735         1.0              0.0   \n",
       "4        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n",
       "0               0.0            1.0             0.0          0.0   \n",
       "1               0.0            0.0             0.0          0.0   \n",
       "2               0.0            0.0             0.0          0.0   \n",
       "3               0.0            0.0             0.0          0.0   \n",
       "4               0.0            0.0             0.0          0.0   \n",
       "\n",
       "   job_self-employed  job_services  job_student  job_technician  \\\n",
       "0                0.0           0.0          0.0             0.0   \n",
       "1                0.0           1.0          0.0             0.0   \n",
       "2                0.0           1.0          0.0             0.0   \n",
       "3                0.0           0.0          0.0             0.0   \n",
       "4                0.0           1.0          0.0             0.0   \n",
       "\n",
       "   job_unemployed  marital_divorced  marital_married  marital_single  \\\n",
       "0             0.0               0.0              1.0             0.0   \n",
       "1             0.0               0.0              1.0             0.0   \n",
       "2             0.0               0.0              1.0             0.0   \n",
       "3             0.0               0.0              1.0             0.0   \n",
       "4             0.0               0.0              1.0             0.0   \n",
       "\n",
       "   default_no  default_yes  housing_no  housing_yes  loan_no  loan_yes  \\\n",
       "0         1.0          0.0         1.0          0.0      1.0       0.0   \n",
       "1         0.0          0.0         1.0          0.0      1.0       0.0   \n",
       "2         1.0          0.0         0.0          1.0      1.0       0.0   \n",
       "3         1.0          0.0         1.0          0.0      1.0       0.0   \n",
       "4         1.0          0.0         1.0          0.0      0.0       1.0   \n",
       "\n",
       "   contact_cellular  month_aug  month_dec  month_jul  month_jun  month_mar  \\\n",
       "0               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   month_may  month_nov  month_oct  month_sep  day_of_week_fri  \\\n",
       "0        1.0        0.0        0.0        0.0              0.0   \n",
       "1        1.0        0.0        0.0        0.0              0.0   \n",
       "2        1.0        0.0        0.0        0.0              0.0   \n",
       "3        1.0        0.0        0.0        0.0              0.0   \n",
       "4        1.0        0.0        0.0        0.0              0.0   \n",
       "\n",
       "   day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "0              0.0              0.0              0.0               0.0   \n",
       "1              0.0              0.0              0.0               0.0   \n",
       "2              0.0              0.0              0.0               0.0   \n",
       "3              0.0              0.0              0.0               0.0   \n",
       "4              0.0              0.0              0.0               0.0   \n",
       "\n",
       "   poutcome_success  edu_ordinal  y_coded  \n",
       "0               0.0     0.285714      0.0  \n",
       "1               0.0     0.714286      0.0  \n",
       "2               0.0     0.714286      0.0  \n",
       "3               0.0     0.428571      0.0  \n",
       "4               0.0     0.714286      0.0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_all_norm = clients_all_norm.drop(['duration'], axis=1) \n",
    "#drop duration variable as suggested by dataset source: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "clients_all_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 46)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Matrix = clients_all_norm.iloc[:,:-1] #Separating dataset into features & target variable\n",
    "X_Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    36537\n",
       "1.0     4639\n",
       "Name: y_coded, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series = clients_all_norm.y_coded #Separating dataset into features & target variable\n",
    "y_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkgreen'>feature selection</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure features are on the same scale before regularisation: https://stats.stackexchange.com/questions/189176/why-do-we-need-to-normalize-data-before-applying-penalizing-methods-in-the-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "EN = ElasticNet(alpha=0.001)\n",
    "\n",
    "EN.fit(X_Matrix, y_series)\n",
    "\n",
    "#Plot the importance of features\n",
    "plt.figure(figsize=(15,15))\n",
    "ft_importances_EN=pd.Series(EN.coef_, index=X_Matrix.columns)\n",
    "ft_importances_EN.plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x106b15c88>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf_cart = tree.DecisionTreeClassifier(random_state=1)\n",
    "impt = clf_cart.fit(X_Matrix,y_series).feature_importances_\n",
    "\n",
    "feat_importances = pd.Series(impt, index=X_Matrix.columns)\n",
    "feat_importances = feat_importances.nlargest(20)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 6.0\n",
      "duration: 2.0\n",
      "campaign: 1.0\n",
      "pdays: 33.0\n",
      "previous: 2.0\n",
      "emp.var.rate: 194.0\n",
      "cons.price.idx: 28.0\n",
      "cons.conf.idx: 7.0\n",
      "euribor3m: 126.0\n",
      "nr.employed: 116.0\n"
     ]
    }
   ],
   "source": [
    "num = clients.select_dtypes(['int64', 'float64'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "num_sc = mms.fit_transform(num)\n",
    "num_sc = pd.DataFrame(num_sc, columns = num.columns) \n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "num_values = num_sc.values #https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array-preserving-index\n",
    "for i in range(10):\n",
    "    j = ['age','duration','campaign', 'pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "    print(str(j[i]) + \": \" + str(round(variance_inflation_factor(num_values, i))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brown'>reduce features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 46)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Matrix = clients_all_norm.iloc[:,:-1] #Separating dataset into features & target variable\n",
    "X_Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    36537\n",
       "1.0     4639\n",
       "Name: y_coded, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_series = clients_all_norm.y_coded #Separating dataset into features & target variable\n",
    "y_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>edu_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "1  0.493827       0.0    1.0       0.0        0.9375        0.698753   \n",
       "2  0.246914       0.0    1.0       0.0        0.9375        0.698753   \n",
       "3  0.283951       0.0    1.0       0.0        0.9375        0.698753   \n",
       "4  0.481481       0.0    1.0       0.0        0.9375        0.698753   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  job_admin.  job_blue-collar  \\\n",
       "0        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "1        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "2        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "3        0.60251   0.957379     0.859735         1.0              0.0   \n",
       "4        0.60251   0.957379     0.859735         0.0              0.0   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n",
       "0               0.0            1.0             0.0          0.0   \n",
       "1               0.0            0.0             0.0          0.0   \n",
       "2               0.0            0.0             0.0          0.0   \n",
       "3               0.0            0.0             0.0          0.0   \n",
       "4               0.0            0.0             0.0          0.0   \n",
       "\n",
       "   job_self-employed  job_services  job_student  job_technician  \\\n",
       "0                0.0           0.0          0.0             0.0   \n",
       "1                0.0           1.0          0.0             0.0   \n",
       "2                0.0           1.0          0.0             0.0   \n",
       "3                0.0           0.0          0.0             0.0   \n",
       "4                0.0           1.0          0.0             0.0   \n",
       "\n",
       "   job_unemployed  marital_divorced  marital_married  marital_single  \\\n",
       "0             0.0               0.0              1.0             0.0   \n",
       "1             0.0               0.0              1.0             0.0   \n",
       "2             0.0               0.0              1.0             0.0   \n",
       "3             0.0               0.0              1.0             0.0   \n",
       "4             0.0               0.0              1.0             0.0   \n",
       "\n",
       "   default_no  default_yes  housing_no  housing_yes  loan_no  loan_yes  \\\n",
       "0         1.0          0.0         1.0          0.0      1.0       0.0   \n",
       "1         0.0          0.0         1.0          0.0      1.0       0.0   \n",
       "2         1.0          0.0         0.0          1.0      1.0       0.0   \n",
       "3         1.0          0.0         1.0          0.0      1.0       0.0   \n",
       "4         1.0          0.0         1.0          0.0      0.0       1.0   \n",
       "\n",
       "   contact_cellular  month_aug  month_dec  month_jul  month_jun  month_mar  \\\n",
       "0               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   month_may  month_nov  month_oct  month_sep  day_of_week_fri  \\\n",
       "0        1.0        0.0        0.0        0.0              0.0   \n",
       "1        1.0        0.0        0.0        0.0              0.0   \n",
       "2        1.0        0.0        0.0        0.0              0.0   \n",
       "3        1.0        0.0        0.0        0.0              0.0   \n",
       "4        1.0        0.0        0.0        0.0              0.0   \n",
       "\n",
       "   day_of_week_thu  day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "0              0.0              0.0              0.0               0.0   \n",
       "1              0.0              0.0              0.0               0.0   \n",
       "2              0.0              0.0              0.0               0.0   \n",
       "3              0.0              0.0              0.0               0.0   \n",
       "4              0.0              0.0              0.0               0.0   \n",
       "\n",
       "   poutcome_success  edu_ordinal  \n",
       "0               0.0     0.285714  \n",
       "1               0.0     0.714286  \n",
       "2               0.0     0.714286  \n",
       "3               0.0     0.428571  \n",
       "4               0.0     0.714286  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>pdays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   poutcome_failure  poutcome_success  nr.employed  cons.price.idx  \\\n",
       "0               0.0               0.0     0.859735        0.698753   \n",
       "1               0.0               0.0     0.859735        0.698753   \n",
       "2               0.0               0.0     0.859735        0.698753   \n",
       "3               0.0               0.0     0.859735        0.698753   \n",
       "4               0.0               0.0     0.859735        0.698753   \n",
       "\n",
       "   cons.conf.idx  emp.var.rate  pdays  \n",
       "0        0.60251        0.9375    1.0  \n",
       "1        0.60251        0.9375    1.0  \n",
       "2        0.60251        0.9375    1.0  \n",
       "3        0.60251        0.9375    1.0  \n",
       "4        0.60251        0.9375    1.0  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Matrix = X_Matrix[['poutcome_failure', 'poutcome_success', 'nr.employed', 'cons.price.idx', \n",
    "                     'cons.conf.idx', 'emp.var.rate', 'pdays']]\n",
    "\n",
    "X_Matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: OVERSAMPLING -Taking Bootstrap samples of minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>LOG REG</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.732\n",
      "accuracy score of test set: 0.764\n",
      "auc score of test set: 0.723\n",
      "recall score of test set: 0.672\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.85     12176\n",
      "        1.0       0.28      0.67      0.39      1550\n",
      "\n",
      "avg / total       0.87      0.76      0.80     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.726\n",
      "accuracy score of test set: 0.768\n",
      "auc score of test set: 0.735\n",
      "recall score of test set: 0.691\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12153\n",
      "        1.0       0.29      0.69      0.41      1572\n",
      "\n",
      "avg / total       0.88      0.77      0.80     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.732\n",
      "accuracy score of test set: 0.771\n",
      "auc score of test set: 0.723\n",
      "recall score of test set: 0.662\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12208\n",
      "        1.0       0.28      0.66      0.39      1517\n",
      "\n",
      "avg / total       0.87      0.77      0.81     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.73, 0.003\n",
      "Test set accuracy for all folds, Mean & Std: 0.767, 0.003\n",
      "Test set auc for all folds, Mean & Std: 0.727, 0.005\n",
      "Test set recall for all folds, Mean & Std: 0.675, 0.012\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    training_set = pd.concat([X_train,y_train], axis=1)\n",
    "    \n",
    "    #from sklearn.utils import resample\n",
    "    training_majority = training_set[training_set.y_coded==0]\n",
    "    training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "    training_minority_upsampled = resample(training_minority, replace=True, n_samples=training_majority.shape[0], random_state=1)\n",
    "    all_training_upsampled = pd.concat([training_majority,training_minority_upsampled], axis=0)\n",
    "\n",
    "    X_train_upsampled = all_training_upsampled.iloc[:,:-1]\n",
    "    y_train_upsampled = all_training_upsampled.iloc[:,-1]\n",
    "\n",
    "    logreg=LogisticRegression(random_state=1)\n",
    "\n",
    "    logreg.fit(X_train_upsampled,y_train_upsampled)\n",
    "    pred_train = logreg.predict(X_train_upsampled)\n",
    "    true_train = y_train_upsampled\n",
    "    pred = logreg.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[8579 2388]\n",
      " [ 414  972]]\n",
      "accuracy score of training set: 0.719\n",
      "accuracy score of test set: 0.773\n",
      "auc score of test set: 0.742\n",
      "recall score of test set: 0.701\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     10967\n",
      "        1.0       0.29      0.70      0.41      1386\n",
      "\n",
      "avg / total       0.88      0.77      0.81     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "training_minority_upsampled = resample(training_minority, replace=True, n_samples=training_majority.shape[0], random_state=1)\n",
    "all_training_upsampled = pd.concat([training_majority,training_minority_upsampled], axis=0)\n",
    "\n",
    "X_train_upsampled = all_training_upsampled.iloc[:,:-1]\n",
    "y_train_upsampled = all_training_upsampled.iloc[:,-1]\n",
    "\n",
    "logreg=LogisticRegression(random_state=1)\n",
    "\n",
    "logreg.fit(X_train_upsampled,y_train_upsampled)\n",
    "pred_train = logreg.predict(X_train_upsampled)\n",
    "true_train = y_train_upsampled\n",
    "pred = logreg.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[5713 1601]\n",
      " [ 278  644]]\n",
      "accuracy score of training set: 0.726\n",
      "accuracy score of test set: 0.772\n",
      "auc score of test set: 0.74\n",
      "recall score of test set: 0.698\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86      7314\n",
      "        1.0       0.29      0.70      0.41       922\n",
      "\n",
      "avg / total       0.88      0.77      0.81      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_minority_upsampled = resample(training_minority, replace=True, n_samples=training_majority.shape[0], random_state=1)\n",
    "all_training_upsampled = pd.concat([training_majority,training_minority_upsampled], axis=0)\n",
    "\n",
    "X_train_upsampled = all_training_upsampled.iloc[:,:-1]\n",
    "y_train_upsampled = all_training_upsampled.iloc[:,-1]\n",
    "\n",
    "logreg=LogisticRegression(random_state=1)\n",
    "\n",
    "logreg.fit(X_train_upsampled,y_train_upsampled)\n",
    "pred_train = logreg.predict(X_train_upsampled)\n",
    "true_train = y_train_upsampled\n",
    "pred = logreg.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>KNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 accuracy of training set: 0.657\n",
      "    accuracy of test set: 0.855\n",
      "    auc of test set: 0.633\n",
      "    recall of test set: 0.348\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92     12229\n",
      "        1.0       0.34      0.35      0.34      1496\n",
      "\n",
      "avg / total       0.86      0.86      0.86     13725\n",
      "\n",
      " \n",
      "K=2 accuracy of training set: 0.596\n",
      "    accuracy of test set: 0.887\n",
      "    auc of test set: 0.583\n",
      "    recall of test set: 0.193\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94     12229\n",
      "        1.0       0.46      0.19      0.27      1496\n",
      "\n",
      "avg / total       0.86      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=3 accuracy of training set: 0.634\n",
      "    accuracy of test set: 0.888\n",
      "    auc of test set: 0.619\n",
      "    recall of test set: 0.275\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     12229\n",
      "        1.0       0.48      0.27      0.35      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=4 accuracy of training set: 0.604\n",
      "    accuracy of test set: 0.887\n",
      "    auc of test set: 0.594\n",
      "    recall of test set: 0.219\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94     12229\n",
      "        1.0       0.46      0.22      0.30      1496\n",
      "\n",
      "avg / total       0.86      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=5 accuracy of training set: 0.633\n",
      "    accuracy of test set: 0.887\n",
      "    auc of test set: 0.618\n",
      "    recall of test set: 0.275\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     12229\n",
      "        1.0       0.47      0.27      0.35      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=6 accuracy of training set: 0.619\n",
      "    accuracy of test set: 0.888\n",
      "    auc of test set: 0.609\n",
      "    recall of test set: 0.251\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94     12229\n",
      "        1.0       0.47      0.25      0.33      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=7 accuracy of training set: 0.63\n",
      "    accuracy of test set: 0.887\n",
      "    auc of test set: 0.619\n",
      "    recall of test set: 0.277\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     12229\n",
      "        1.0       0.47      0.28      0.35      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=8 accuracy of training set: 0.616\n",
      "    accuracy of test set: 0.889\n",
      "    auc of test set: 0.607\n",
      "    recall of test set: 0.247\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94     12229\n",
      "        1.0       0.48      0.25      0.33      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for i in range(1,9):\n",
    "    for train_index, test_index in kf.split(clients_all_norm):\n",
    "        X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "        y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "        training_set = pd.concat([X_train,y_train], axis=1)\n",
    "    \n",
    "        training_majority = training_set[training_set.y_coded==0]\n",
    "        training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "        #from sklearn.utils import resample\n",
    "        training_minority_upsampled = resample(training_minority, replace=True, n_samples=training_majority.shape[0], random_state=1)\n",
    "        all_training_upsampled = pd.concat([training_majority,training_minority_upsampled], axis=0)\n",
    "\n",
    "        X_train_upsampled = all_training_upsampled.iloc[:,:-1]\n",
    "        y_train_upsampled = all_training_upsampled.iloc[:,-1]\n",
    "    \n",
    "        knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "        knn.fit(X_train_upsampled, y_train_upsampled)\n",
    "    \n",
    "        pred_train = knn.predict(X_train_upsampled)\n",
    "        true_train = y_train_upsampled\n",
    "        pred = knn.predict(X_test)\n",
    "        true = y_test\n",
    "    \n",
    "    print(\"K=\"+ str(i)+ \" \" +\"accuracy of training set: \" + str(round(metrics.accuracy_score(true_train, pred_train),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"accuracy of test set: \" + str(round(metrics.accuracy_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"auc of test set: \" + str(round(metrics.roc_auc_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"recall of test set: \" + str(round(metrics.recall_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[10501   466]\n",
      " [ 1035   351]]\n",
      "accuracy score of training set: 0.612\n",
      "accuracy score of test set: 0.878\n",
      "auc score of test set: 0.605\n",
      "recall score of test set: 0.253\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.96      0.93     10967\n",
      "        1.0       0.43      0.25      0.32      1386\n",
      "\n",
      "avg / total       0.86      0.88      0.86     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_minority_upsampled = resample(training_minority, replace=True, n_samples=training_majority.shape[0], random_state=1)\n",
    "all_training_upsampled = pd.concat([training_majority,training_minority_upsampled], axis=0)\n",
    "\n",
    "X_train_upsampled = all_training_upsampled.iloc[:,:-1]\n",
    "y_train_upsampled = all_training_upsampled.iloc[:,-1]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "\n",
    "knn.fit(X_train_upsampled,y_train_upsampled)\n",
    "pred_train = knn.predict(X_train_upsampled)\n",
    "true_train = y_train_upsampled\n",
    "pred = knn.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[7095  219]\n",
      " [ 713  209]]\n",
      "accuracy score of training set: 0.61\n",
      "accuracy score of test set: 0.887\n",
      "auc score of test set: 0.598\n",
      "recall score of test set: 0.227\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94      7314\n",
      "        1.0       0.49      0.23      0.31       922\n",
      "\n",
      "avg / total       0.86      0.89      0.87      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_minority_upsampled = resample(training_minority, replace=True, n_samples=training_majority.shape[0], random_state=1)\n",
    "all_training_upsampled = pd.concat([training_majority,training_minority_upsampled], axis=0)\n",
    "\n",
    "X_train_upsampled = all_training_upsampled.iloc[:,:-1]\n",
    "y_train_upsampled = all_training_upsampled.iloc[:,-1]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "\n",
    "knn.fit(X_train_upsampled,y_train_upsampled)\n",
    "pred_train = knn.predict(X_train_upsampled)\n",
    "true_train = y_train_upsampled\n",
    "pred = knn.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>SVM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>CART</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>RF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>NN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>AdaBoost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Gradient Boost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>XG Boost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: UNDERSAMPLING -Taking smaller samples of majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>LOG REG</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.735\n",
      "accuracy score of test set: 0.767\n",
      "auc score of test set: 0.721\n",
      "recall score of test set: 0.662\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12221\n",
      "        1.0       0.27      0.66      0.38      1505\n",
      "\n",
      "avg / total       0.87      0.77      0.80     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.727\n",
      "accuracy score of test set: 0.768\n",
      "auc score of test set: 0.732\n",
      "recall score of test set: 0.685\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12182\n",
      "        1.0       0.28      0.69      0.40      1543\n",
      "\n",
      "avg / total       0.88      0.77      0.80     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.727\n",
      "accuracy score of test set: 0.767\n",
      "auc score of test set: 0.728\n",
      "recall score of test set: 0.678\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12134\n",
      "        1.0       0.29      0.68      0.40      1591\n",
      "\n",
      "avg / total       0.87      0.77      0.80     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.729, 0.004\n",
      "Test set accuracy for all folds, Mean & Std: 0.767, 0.0\n",
      "Test set auc for all folds, Mean & Std: 0.727, 0.004\n",
      "Test set recall for all folds, Mean & Std: 0.675, 0.009\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    training_set = pd.concat([X_train,y_train], axis=1)\n",
    "    \n",
    "    training_majority = training_set[training_set.y_coded==0]\n",
    "    training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "    #from sklearn.utils import resample\n",
    "    training_majority_downsampled = resample(training_majority, replace=True, n_samples=training_minority.shape[0], random_state=1)\n",
    "    all_training_downsampled = pd.concat([training_majority_downsampled,training_minority], axis=0)\n",
    "\n",
    "    X_train_downsampled = all_training_downsampled.iloc[:,:-1]\n",
    "    y_train_downsampled = all_training_downsampled.iloc[:,-1]\n",
    "\n",
    "    logreg=LogisticRegression(random_state=1)\n",
    "\n",
    "    logreg.fit(X_train_downsampled,y_train_downsampled)\n",
    "    pred_train = logreg.predict(X_train_downsampled)\n",
    "    true_train = y_train_downsampled\n",
    "    pred = logreg.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[8579 2388]\n",
      " [ 414  972]]\n",
      "accuracy score of training set: 0.727\n",
      "accuracy score of test set: 0.773\n",
      "auc score of test set: 0.742\n",
      "recall score of test set: 0.701\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     10967\n",
      "        1.0       0.29      0.70      0.41      1386\n",
      "\n",
      "avg / total       0.88      0.77      0.81     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_majority_downsampled = resample(training_majority, replace=True, n_samples=training_minority.shape[0], random_state=1)\n",
    "all_training_downsampled = pd.concat([training_majority_downsampled,training_minority], axis=0)\n",
    "\n",
    "X_train_downsampled = all_training_downsampled.iloc[:,:-1]\n",
    "y_train_downsampled = all_training_downsampled.iloc[:,-1]\n",
    "\n",
    "logreg=LogisticRegression(random_state=1)\n",
    "\n",
    "logreg.fit(X_train_downsampled,y_train_downsampled)\n",
    "pred_train = logreg.predict(X_train_downsampled)\n",
    "true_train = y_train_downsampled\n",
    "pred = logreg.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[5713 1601]\n",
      " [ 278  644]]\n",
      "accuracy score of training set: 0.725\n",
      "accuracy score of test set: 0.772\n",
      "auc score of test set: 0.74\n",
      "recall score of test set: 0.698\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86      7314\n",
      "        1.0       0.29      0.70      0.41       922\n",
      "\n",
      "avg / total       0.88      0.77      0.81      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_majority_downsampled = resample(training_majority, replace=True, n_samples=training_minority.shape[0], random_state=1)\n",
    "all_training_downsampled = pd.concat([training_majority_downsampled,training_minority], axis=0)\n",
    "\n",
    "X_train_downsampled = all_training_downsampled.iloc[:,:-1]\n",
    "y_train_downsampled = all_training_downsampled.iloc[:,-1]\n",
    "\n",
    "logreg=LogisticRegression(random_state=1)\n",
    "\n",
    "logreg.fit(X_train_downsampled,y_train_downsampled)\n",
    "pred_train = logreg.predict(X_train_downsampled)\n",
    "true_train = y_train_downsampled\n",
    "pred = logreg.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>KNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 accuracy of training set: 0.576\n",
      "    accuracy of test set: 0.842\n",
      "    auc of test set: 0.559\n",
      "    recall of test set: 0.196\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.92      0.91     12229\n",
      "        1.0       0.23      0.20      0.21      1496\n",
      "\n",
      "avg / total       0.83      0.84      0.84     13725\n",
      "\n",
      " \n",
      "K=2 accuracy of training set: 0.581\n",
      "    accuracy of test set: 0.879\n",
      "    auc of test set: 0.564\n",
      "    recall of test set: 0.162\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.97      0.93     12229\n",
      "        1.0       0.37      0.16      0.23      1496\n",
      "\n",
      "avg / total       0.85      0.88      0.86     13725\n",
      "\n",
      " \n",
      "K=3 accuracy of training set: 0.609\n",
      "    accuracy of test set: 0.878\n",
      "    auc of test set: 0.591\n",
      "    recall of test set: 0.225\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.96      0.93     12229\n",
      "        1.0       0.39      0.22      0.29      1496\n",
      "\n",
      "avg / total       0.85      0.88      0.86     13725\n",
      "\n",
      " \n",
      "K=4 accuracy of training set: 0.603\n",
      "    accuracy of test set: 0.879\n",
      "    auc of test set: 0.585\n",
      "    recall of test set: 0.208\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.96      0.93     12229\n",
      "        1.0       0.40      0.21      0.27      1496\n",
      "\n",
      "avg / total       0.85      0.88      0.86     13725\n",
      "\n",
      " \n",
      "K=5 accuracy of training set: 0.622\n",
      "    accuracy of test set: 0.842\n",
      "    auc of test set: 0.607\n",
      "    recall of test set: 0.307\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.91      0.91     12229\n",
      "        1.0       0.29      0.31      0.30      1496\n",
      "\n",
      "avg / total       0.85      0.84      0.84     13725\n",
      "\n",
      " \n",
      "K=6 accuracy of training set: 0.622\n",
      "    accuracy of test set: 0.842\n",
      "    auc of test set: 0.607\n",
      "    recall of test set: 0.305\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.91      0.91     12229\n",
      "        1.0       0.29      0.31      0.30      1496\n",
      "\n",
      "avg / total       0.85      0.84      0.84     13725\n",
      "\n",
      " \n",
      "K=7 accuracy of training set: 0.637\n",
      "    accuracy of test set: 0.844\n",
      "    auc of test set: 0.625\n",
      "    recall of test set: 0.346\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.90      0.91     12229\n",
      "        1.0       0.31      0.35      0.33      1496\n",
      "\n",
      "avg / total       0.85      0.84      0.85     13725\n",
      "\n",
      " \n",
      "K=8 accuracy of training set: 0.646\n",
      "    accuracy of test set: 0.879\n",
      "    auc of test set: 0.636\n",
      "    recall of test set: 0.324\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.95      0.93     12229\n",
      "        1.0       0.43      0.32      0.37      1496\n",
      "\n",
      "avg / total       0.87      0.88      0.87     13725\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for i in range(1,9):\n",
    "    for train_index, test_index in kf.split(clients_all_norm):\n",
    "        X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "        y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "        training_set = pd.concat([X_train,y_train], axis=1)\n",
    "    \n",
    "        training_majority = training_set[training_set.y_coded==0]\n",
    "        training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "        #from sklearn.utils import resample\n",
    "        training_majority_downsampled = resample(training_majority, replace=True, n_samples=training_minority.shape[0], random_state=1)\n",
    "        all_training_downsampled = pd.concat([training_majority_downsampled,training_minority], axis=0)\n",
    "\n",
    "        X_train_downsampled = all_training_downsampled.iloc[:,:-1]\n",
    "        y_train_downsampled = all_training_downsampled.iloc[:,-1]\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "        knn.fit(X_train_downsampled, y_train_downsampled)\n",
    "    \n",
    "        pred_train = knn.predict(X_train_downsampled)\n",
    "        true_train = y_train_downsampled\n",
    "        pred = knn.predict(X_test)\n",
    "        true = y_test\n",
    "    \n",
    "    print(\"K=\"+ str(i)+ \" \" +\"accuracy of training set: \" + str(round(metrics.accuracy_score(true_train, pred_train),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"accuracy of test set: \" + str(round(metrics.accuracy_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"auc of test set: \" + str(round(metrics.roc_auc_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"recall of test set: \" + str(round(metrics.recall_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[10573   394]\n",
      " [  945   441]]\n",
      "accuracy score of training set: 0.641\n",
      "accuracy score of test set: 0.892\n",
      "auc score of test set: 0.641\n",
      "recall score of test set: 0.318\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     10967\n",
      "        1.0       0.53      0.32      0.40      1386\n",
      "\n",
      "avg / total       0.87      0.89      0.88     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_majority_downsampled = resample(training_majority, replace=True, n_samples=training_minority.shape[0], random_state=1)\n",
    "all_training_downsampled = pd.concat([training_majority_downsampled,training_minority], axis=0)\n",
    "\n",
    "X_train_downsampled = all_training_downsampled.iloc[:,:-1]\n",
    "y_train_downsampled = all_training_downsampled.iloc[:,-1]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "knn.fit(X_train_downsampled, y_train_downsampled)\n",
    "    \n",
    "pred_train = knn.predict(X_train_downsampled)\n",
    "true_train = y_train_downsampled\n",
    "pred = knn.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[7071  243]\n",
      " [ 651  271]]\n",
      "accuracy score of training set: 0.629\n",
      "accuracy score of test set: 0.891\n",
      "auc score of test set: 0.63\n",
      "recall score of test set: 0.294\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.97      0.94      7314\n",
      "        1.0       0.53      0.29      0.38       922\n",
      "\n",
      "avg / total       0.87      0.89      0.88      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "training_set = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "training_majority = training_set[training_set.y_coded==0]\n",
    "training_minority = training_set[training_set.y_coded==1]\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "training_majority_downsampled = resample(training_majority, replace=True, n_samples=training_minority.shape[0], random_state=1)\n",
    "all_training_downsampled = pd.concat([training_majority_downsampled,training_minority], axis=0)\n",
    "\n",
    "X_train_downsampled = all_training_downsampled.iloc[:,:-1]\n",
    "y_train_downsampled = all_training_downsampled.iloc[:,-1]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "knn.fit(X_train_downsampled, y_train_downsampled)\n",
    "    \n",
    "pred_train = knn.predict(X_train_downsampled)\n",
    "true_train = y_train_downsampled\n",
    "pred = knn.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"confusion matrix: \") \n",
    "print(str(metrics.confusion_matrix(true, pred)))\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>SVM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>CART</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>RF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>NN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>AdaBoost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Gradient Boost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>XG Boost</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Rebalancing using SMOTETomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>LOG REG</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validate, test = np.split(clients_all_norm.sample(frac=1), [int(.6*len(clients_all_norm)), int(.8*len(clients_all_norm))])\n",
    "#print(train.shape)\n",
    "#print(validate.shape)\n",
    "#print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "sm = SMOTETomek()\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.735\n",
      "accuracy score of test set: 0.766\n",
      "auc score of test set: 0.713\n",
      "recall score of test set: 0.646\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12180\n",
      "        1.0       0.27      0.65      0.38      1546\n",
      "\n",
      "avg / total       0.87      0.77      0.80     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.723\n",
      "accuracy score of test set: 0.769\n",
      "auc score of test set: 0.736\n",
      "recall score of test set: 0.694\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12165\n",
      "        1.0       0.29      0.69      0.41      1560\n",
      "\n",
      "avg / total       0.88      0.77      0.81     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.723\n",
      "accuracy score of test set: 0.767\n",
      "auc score of test set: 0.732\n",
      "recall score of test set: 0.686\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12192\n",
      "        1.0       0.28      0.69      0.40      1533\n",
      "\n",
      "avg / total       0.88      0.77      0.80     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.727, 0.006\n",
      "Test set accuracy for all folds, Mean & Std: 0.767, 0.001\n",
      "Test set auc for all folds, Mean & Std: 0.727, 0.01\n",
      "Test set recall for all folds, Mean & Std: 0.675, 0.021\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    logreg.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = logreg.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = logreg.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5722762 ,  0.20428641, -1.61392436,  0.73539622,  0.49311891,\n",
       "        -1.72518408, -1.25732514]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients of model\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56423965, 1.22664943, 0.19910472, 2.08630846, 1.63741521,\n",
       "        0.17814026, 0.28441378]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#odds\n",
    "odds = np.exp(logreg.coef_)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5722762 ,  0.20428641, -1.61392436,  0.73539622,  0.49311891,\n",
       "        -1.72518408, -1.25732514]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log_odds\n",
    "log_odds = np.log(np.exp(logreg.coef_))\n",
    "log_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36071177, 0.55089473, 0.16604448, 0.67598832, 0.62084089,\n",
       "        0.15120463, 0.2214347 ]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prob\n",
    "prob = odds/(1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef = pd.DataFrame(logreg.coef_, columns=X_Matrix.columns).T\n",
    "#for i in logreg.coef_: \n",
    "    #print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>coef</th>\n",
       "      <th>odds</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poutcome_failure</td>\n",
       "      <td>-0.572276</td>\n",
       "      <td>0.564240</td>\n",
       "      <td>0.360712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poutcome_success</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>1.226649</td>\n",
       "      <td>0.550895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nr.employed</td>\n",
       "      <td>-1.613924</td>\n",
       "      <td>0.199105</td>\n",
       "      <td>0.166044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cons.price.idx</td>\n",
       "      <td>0.735396</td>\n",
       "      <td>2.086308</td>\n",
       "      <td>0.675988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.493119</td>\n",
       "      <td>1.637415</td>\n",
       "      <td>0.620841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>-1.725184</td>\n",
       "      <td>0.178140</td>\n",
       "      <td>0.151205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pdays</td>\n",
       "      <td>-1.257325</td>\n",
       "      <td>0.284414</td>\n",
       "      <td>0.221435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      coef      odds      prob\n",
       "0  poutcome_failure -0.572276  0.564240  0.360712\n",
       "1  poutcome_success  0.204286  1.226649  0.550895\n",
       "2       nr.employed -1.613924  0.199105  0.166044\n",
       "3    cons.price.idx  0.735396  2.086308  0.675988\n",
       "4     cons.conf.idx  0.493119  1.637415  0.620841\n",
       "5      emp.var.rate -1.725184  0.178140  0.151205\n",
       "6             pdays -1.257325  0.284414  0.221435"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(X_Matrix.columns.tolist())\n",
    "table['coef'] = pd.DataFrame({'coef':i for i in logreg.coef_})\n",
    "table['odds'] = pd.DataFrame({'odds':i for i in odds})\n",
    "table['prob'] = pd.DataFrame({'prob':i for i in prob})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.724\n",
      "accuracy score of test set: 0.767\n",
      "auc score of test set: 0.737\n",
      "recall score of test set: 0.7\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.77      0.86      7337\n",
      "        1.0       0.28      0.70      0.40       899\n",
      "\n",
      "avg / total       0.88      0.77      0.81      8236\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.725\n",
      "accuracy score of test set: 0.77\n",
      "auc score of test set: 0.728\n",
      "recall score of test set: 0.674\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86      7291\n",
      "        1.0       0.29      0.67      0.40       944\n",
      "\n",
      "avg / total       0.87      0.77      0.81      8235\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.728\n",
      "accuracy score of test set: 0.762\n",
      "auc score of test set: 0.718\n",
      "recall score of test set: 0.661\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.77      0.85      7305\n",
      "        1.0       0.27      0.66      0.39       930\n",
      "\n",
      "avg / total       0.87      0.76      0.80      8235\n",
      "\n",
      " \n",
      "Fold 4:\n",
      "accuracy score of training set: 0.732\n",
      "accuracy score of test set: 0.761\n",
      "auc score of test set: 0.714\n",
      "recall score of test set: 0.653\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.77      0.85      7291\n",
      "        1.0       0.27      0.65      0.38       944\n",
      "\n",
      "avg / total       0.87      0.76      0.80      8235\n",
      "\n",
      " \n",
      "Fold 5:\n",
      "accuracy score of training set: 0.726\n",
      "accuracy score of test set: 0.777\n",
      "auc score of test set: 0.739\n",
      "recall score of test set: 0.69\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.79      0.86      7313\n",
      "        1.0       0.29      0.69      0.41       922\n",
      "\n",
      "avg / total       0.88      0.78      0.81      8235\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.727, 0.003\n",
      "Test set accuracy for all folds, Mean & Std: 0.767, 0.006\n",
      "Test set auc for all folds, Mean & Std: 0.727, 0.01\n",
      "Test set recall for all folds, Mean & Std: 0.675, 0.017\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    logreg.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = logreg.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = logreg.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.721\n",
      "accuracy score of test set: 0.773\n",
      "auc score of test set: 0.742\n",
      "recall score of test set: 0.701\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     10967\n",
      "        1.0       0.29      0.70      0.41      1386\n",
      "\n",
      "avg / total       0.88      0.77      0.81     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "logreg.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = logreg.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = logreg.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.726\n",
      "accuracy score of test set: 0.772\n",
      "auc score of test set: 0.74\n",
      "recall score of test set: 0.698\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86      7314\n",
      "        1.0       0.29      0.70      0.41       922\n",
      "\n",
      "avg / total       0.88      0.77      0.81      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "logreg.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = logreg.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = logreg.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289602\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>y_coded</td>     <th>  No. Observations:  </th>  <td> 28823</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 28816</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 19 Jul 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.1783</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>00:20:32</td>     <th>  Log-Likelihood:    </th> <td> -8347.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -10159.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poutcome_failure</th> <td>   -0.3710</td> <td>    0.060</td> <td>   -6.133</td> <td> 0.000</td> <td>   -0.490</td> <td>   -0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poutcome_success</th> <td>    0.5497</td> <td>    0.116</td> <td>    4.726</td> <td> 0.000</td> <td>    0.322</td> <td>    0.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nr.employed</th>      <td>   -0.9639</td> <td>    0.223</td> <td>   -4.332</td> <td> 0.000</td> <td>   -1.400</td> <td>   -0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cons.price.idx</th>   <td>    1.6506</td> <td>    0.215</td> <td>    7.680</td> <td> 0.000</td> <td>    1.229</td> <td>    2.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cons.conf.idx</th>    <td>    0.6972</td> <td>    0.086</td> <td>    8.110</td> <td> 0.000</td> <td>    0.529</td> <td>    0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp.var.rate</th>     <td>   -2.6161</td> <td>    0.281</td> <td>   -9.311</td> <td> 0.000</td> <td>   -3.167</td> <td>   -2.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pdays</th>            <td>   -0.9863</td> <td>    0.101</td> <td>   -9.740</td> <td> 0.000</td> <td>   -1.185</td> <td>   -0.788</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                y_coded   No. Observations:                28823\n",
       "Model:                          Logit   Df Residuals:                    28816\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Thu, 19 Jul 2018   Pseudo R-squ.:                  0.1783\n",
       "Time:                        00:20:32   Log-Likelihood:                -8347.2\n",
       "converged:                       True   LL-Null:                       -10159.\n",
       "                                        LLR p-value:                     0.000\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "poutcome_failure    -0.3710      0.060     -6.133      0.000      -0.490      -0.252\n",
       "poutcome_success     0.5497      0.116      4.726      0.000       0.322       0.778\n",
       "nr.employed         -0.9639      0.223     -4.332      0.000      -1.400      -0.528\n",
       "cons.price.idx       1.6506      0.215      7.680      0.000       1.229       2.072\n",
       "cons.conf.idx        0.6972      0.086      8.110      0.000       0.529       0.866\n",
       "emp.var.rate        -2.6161      0.281     -9.311      0.000      -3.167      -2.065\n",
       "pdays               -0.9863      0.101     -9.740      0.000      -1.185      -0.788\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smo\n",
    "model = smo.Logit(y_train, X_train)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>KNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 accuracy of training set: 0.655\n",
      "    accuracy of test set: 0.874\n",
      "    auc of test set: 0.633\n",
      "    recall of test set: 0.326\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.94      0.93     12229\n",
      "        1.0       0.40      0.33      0.36      1496\n",
      "\n",
      "avg / total       0.86      0.87      0.87     13725\n",
      "\n",
      " \n",
      "K=2 accuracy of training set: 0.597\n",
      "    accuracy of test set: 0.84\n",
      "    auc of test set: 0.58\n",
      "    recall of test set: 0.248\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.91      0.91     12229\n",
      "        1.0       0.26      0.25      0.25      1496\n",
      "\n",
      "avg / total       0.84      0.84      0.84     13725\n",
      "\n",
      " \n",
      "K=3 accuracy of training set: 0.651\n",
      "    accuracy of test set: 0.879\n",
      "    auc of test set: 0.63\n",
      "    recall of test set: 0.313\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.95      0.93     12229\n",
      "        1.0       0.42      0.31      0.36      1496\n",
      "\n",
      "avg / total       0.86      0.88      0.87     13725\n",
      "\n",
      " \n",
      "K=4 accuracy of training set: 0.645\n",
      "    accuracy of test set: 0.887\n",
      "    auc of test set: 0.619\n",
      "    recall of test set: 0.277\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     12229\n",
      "        1.0       0.47      0.28      0.35      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=5 accuracy of training set: 0.648\n",
      "    accuracy of test set: 0.843\n",
      "    auc of test set: 0.635\n",
      "    recall of test set: 0.37\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.90      0.91     12229\n",
      "        1.0       0.31      0.37      0.34      1496\n",
      "\n",
      "avg / total       0.85      0.84      0.85     13725\n",
      "\n",
      " \n",
      "K=6 accuracy of training set: 0.65\n",
      "    accuracy of test set: 0.885\n",
      "    auc of test set: 0.628\n",
      "    recall of test set: 0.3\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     12229\n",
      "        1.0       0.46      0.30      0.36      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.87     13725\n",
      "\n",
      " \n",
      "K=7 accuracy of training set: 0.652\n",
      "    accuracy of test set: 0.89\n",
      "    auc of test set: 0.634\n",
      "    recall of test set: 0.307\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94     12229\n",
      "        1.0       0.49      0.31      0.38      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.88     13725\n",
      "\n",
      " \n",
      "K=8 accuracy of training set: 0.64\n",
      "    accuracy of test set: 0.89\n",
      "    auc of test set: 0.623\n",
      "    recall of test set: 0.281\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.97      0.94     12229\n",
      "        1.0       0.50      0.28      0.36      1496\n",
      "\n",
      "avg / total       0.87      0.89      0.88     13725\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for i in range(1,9):\n",
    "    for train_index, test_index in kf.split(clients_all_norm):\n",
    "        X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "        y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "        X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "        knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "        knn.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "        pred_train = knn.predict(X_train_resampled)\n",
    "        true_train = y_train_resampled\n",
    "        pred = knn.predict(X_test)\n",
    "        true = y_test\n",
    "    \n",
    "    print(\"K=\"+ str(i)+ \" \" +\"accuracy of training set: \" + str(round(metrics.accuracy_score(true_train, pred_train),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"accuracy of test set: \" + str(round(metrics.accuracy_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"auc of test set: \" + str(round(metrics.roc_auc_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"recall of test set: \" + str(round(metrics.recall_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 accuracy of training set: 0.623\n",
      "    accuracy of test set: 0.804\n",
      "    auc of test set: 0.609\n",
      "    recall of test set: 0.358\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.86      0.89     10967\n",
      "        1.0       0.24      0.36      0.29      1386\n",
      "\n",
      "avg / total       0.84      0.80      0.82     12353\n",
      "\n",
      " \n",
      "K=2 accuracy of training set: 0.604\n",
      "    accuracy of test set: 0.887\n",
      "    auc of test set: 0.581\n",
      "    recall of test set: 0.186\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.98      0.94     10967\n",
      "        1.0       0.49      0.19      0.27      1386\n",
      "\n",
      "avg / total       0.86      0.89      0.86     12353\n",
      "\n",
      " \n",
      "K=3 accuracy of training set: 0.638\n",
      "    accuracy of test set: 0.851\n",
      "    auc of test set: 0.625\n",
      "    recall of test set: 0.335\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92     10967\n",
      "        1.0       0.33      0.33      0.33      1386\n",
      "\n",
      "avg / total       0.85      0.85      0.85     12353\n",
      "\n",
      " \n",
      "K=4 accuracy of training set: 0.627\n",
      "    accuracy of test set: 0.891\n",
      "    auc of test set: 0.615\n",
      "    recall of test set: 0.26\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94     10967\n",
      "        1.0       0.52      0.26      0.35      1386\n",
      "\n",
      "avg / total       0.87      0.89      0.87     12353\n",
      "\n",
      " \n",
      "K=5 accuracy of training set: 0.669\n",
      "    accuracy of test set: 0.861\n",
      "    auc of test set: 0.659\n",
      "    recall of test set: 0.398\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92     10967\n",
      "        1.0       0.38      0.40      0.39      1386\n",
      "\n",
      "avg / total       0.86      0.86      0.86     12353\n",
      "\n",
      " \n",
      "K=6 accuracy of training set: 0.65\n",
      "    accuracy of test set: 0.865\n",
      "    auc of test set: 0.642\n",
      "    recall of test set: 0.354\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.93      0.92     10967\n",
      "        1.0       0.39      0.35      0.37      1386\n",
      "\n",
      "avg / total       0.86      0.86      0.86     12353\n",
      "\n",
      " \n",
      "K=7 accuracy of training set: 0.67\n",
      "    accuracy of test set: 0.865\n",
      "    auc of test set: 0.666\n",
      "    recall of test set: 0.409\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.92      0.92     10967\n",
      "        1.0       0.40      0.41      0.40      1386\n",
      "\n",
      "avg / total       0.87      0.86      0.87     12353\n",
      "\n",
      " \n",
      "K=8 accuracy of training set: 0.628\n",
      "    accuracy of test set: 0.892\n",
      "    auc of test set: 0.625\n",
      "    recall of test set: 0.281\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94     10967\n",
      "        1.0       0.53      0.28      0.37      1386\n",
      "\n",
      "avg / total       0.87      0.89      0.88     12353\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "for i in range(1,9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "    knn.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    pred_train = knn.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = knn.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    print(\"K=\"+ str(i)+ \" \" +\"accuracy of training set: \" + str(round(metrics.accuracy_score(true_train, pred_train),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"accuracy of test set: \" + str(round(metrics.accuracy_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"auc of test set: \" + str(round(metrics.roc_auc_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"recall of test set: \" + str(round(metrics.recall_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1 accuracy of training set: 0.639\n",
      "    accuracy of test set: 0.84\n",
      "    auc of test set: 0.612\n",
      "    recall of test set: 0.318\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.91      0.91      7314\n",
      "        1.0       0.30      0.32      0.31       922\n",
      "\n",
      "avg / total       0.84      0.84      0.84      8236\n",
      "\n",
      " \n",
      "K=2 accuracy of training set: 0.612\n",
      "    accuracy of test set: 0.883\n",
      "    auc of test set: 0.586\n",
      "    recall of test set: 0.204\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.97      0.94      7314\n",
      "        1.0       0.45      0.20      0.28       922\n",
      "\n",
      "avg / total       0.86      0.88      0.86      8236\n",
      "\n",
      " \n",
      "K=3 accuracy of training set: 0.654\n",
      "    accuracy of test set: 0.869\n",
      "    auc of test set: 0.637\n",
      "    recall of test set: 0.337\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.94      0.93      7314\n",
      "        1.0       0.40      0.34      0.37       922\n",
      "\n",
      "avg / total       0.86      0.87      0.86      8236\n",
      "\n",
      " \n",
      "K=4 accuracy of training set: 0.624\n",
      "    accuracy of test set: 0.872\n",
      "    auc of test set: 0.607\n",
      "    recall of test set: 0.265\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.95      0.93      7314\n",
      "        1.0       0.40      0.26      0.32       922\n",
      "\n",
      "avg / total       0.85      0.87      0.86      8236\n",
      "\n",
      " \n",
      "K=5 accuracy of training set: 0.655\n",
      "    accuracy of test set: 0.87\n",
      "    auc of test set: 0.64\n",
      "    recall of test set: 0.344\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.94      0.93      7314\n",
      "        1.0       0.41      0.34      0.37       922\n",
      "\n",
      "avg / total       0.86      0.87      0.87      8236\n",
      "\n",
      " \n",
      "K=6 accuracy of training set: 0.639\n",
      "    accuracy of test set: 0.884\n",
      "    auc of test set: 0.619\n",
      "    recall of test set: 0.278\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.96      0.94      7314\n",
      "        1.0       0.47      0.28      0.35       922\n",
      "\n",
      "avg / total       0.86      0.88      0.87      8236\n",
      "\n",
      " \n",
      "K=7 accuracy of training set: 0.651\n",
      "    accuracy of test set: 0.881\n",
      "    auc of test set: 0.634\n",
      "    recall of test set: 0.316\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.95      0.93      7314\n",
      "        1.0       0.45      0.32      0.37       922\n",
      "\n",
      "avg / total       0.87      0.88      0.87      8236\n",
      "\n",
      " \n",
      "K=8 accuracy of training set: 0.644\n",
      "    accuracy of test set: 0.882\n",
      "    auc of test set: 0.626\n",
      "    recall of test set: 0.296\n",
      "    classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.93      7314\n",
      "        1.0       0.46      0.30      0.36       922\n",
      "\n",
      "avg / total       0.86      0.88      0.87      8236\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "for i in range(1,9):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, n_jobs=-1) #instantiate knn class\n",
    "    knn.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    pred_train = knn.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = knn.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    print(\"K=\"+ str(i)+ \" \" +\"accuracy of training set: \" + str(round(metrics.accuracy_score(true_train, pred_train),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"accuracy of test set: \" + str(round(metrics.accuracy_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"auc of test set: \" + str(round(metrics.roc_auc_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"recall of test set: \" + str(round(metrics.recall_score(true, pred),3)))\n",
    "    print(\"  \"+ \" \"+ \" \" +\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>SVM</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.727\n",
      "accuracy score of test set: 0.767\n",
      "auc score of test set: 0.727\n",
      "recall score of test set: 0.675\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12174\n",
      "        1.0       0.28      0.68      0.40      1552\n",
      "\n",
      "avg / total       0.87      0.77      0.80     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.724\n",
      "accuracy score of test set: 0.771\n",
      "auc score of test set: 0.731\n",
      "recall score of test set: 0.68\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12192\n",
      "        1.0       0.28      0.68      0.40      1533\n",
      "\n",
      "avg / total       0.88      0.77      0.81     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.728\n",
      "accuracy score of test set: 0.765\n",
      "auc score of test set: 0.723\n",
      "recall score of test set: 0.668\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.85     12171\n",
      "        1.0       0.28      0.67      0.39      1554\n",
      "\n",
      "avg / total       0.87      0.77      0.80     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.726, 0.001\n",
      "Test set accuracy for all folds, Mean & Std: 0.768, 0.002\n",
      "Test set auc for all folds, Mean & Std: 0.727, 0.003\n",
      "Test set recall for all folds, Mean & Std: 0.674, 0.005\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_svm.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = clf_svm.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = clf_svm.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.72\n",
      "accuracy score of test set: 0.773\n",
      "auc score of test set: 0.742\n",
      "recall score of test set: 0.701\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     10967\n",
      "        1.0       0.29      0.70      0.41      1386\n",
      "\n",
      "avg / total       0.88      0.77      0.81     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_svm.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_svm.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_svm.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.723\n",
      "accuracy score of test set: 0.772\n",
      "auc score of test set: 0.739\n",
      "recall score of test set: 0.697\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86      7314\n",
      "        1.0       0.29      0.70      0.41       922\n",
      "\n",
      "avg / total       0.88      0.77      0.81      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_svm.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_svm.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_svm.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>CART</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf_cart = tree.DecisionTreeClassifier(random_state=1, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.734\n",
      "accuracy score of test set: 0.835\n",
      "auc score of test set: 0.747\n",
      "recall score of test set: 0.633\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.86      0.90     12194\n",
      "        1.0       0.36      0.63      0.46      1532\n",
      "\n",
      "avg / total       0.88      0.84      0.85     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.74\n",
      "accuracy score of test set: 0.843\n",
      "auc score of test set: 0.729\n",
      "recall score of test set: 0.582\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91     12155\n",
      "        1.0       0.38      0.58      0.46      1570\n",
      "\n",
      "avg / total       0.88      0.84      0.86     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.742\n",
      "accuracy score of test set: 0.832\n",
      "auc score of test set: 0.727\n",
      "recall score of test set: 0.59\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.86      0.90     12188\n",
      "        1.0       0.35      0.59      0.44      1537\n",
      "\n",
      "avg / total       0.88      0.83      0.85     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.738, 0.003\n",
      "Test set accuracy for all folds, Mean & Std: 0.837, 0.005\n",
      "Test set auc for all folds, Mean & Std: 0.734, 0.009\n",
      "Test set recall for all folds, Mean & Std: 0.602, 0.023\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_cart.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = clf_cart.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = clf_cart.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1796pt\" height=\"477pt\"\n",
       " viewBox=\"0.00 0.00 1796.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-473 1792,-473 1792,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"926,-469 811,-469 811,-401 926,-401 926,-469\"/>\n",
       "<text text-anchor=\"middle\" x=\"868.5\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 0.508</text>\n",
       "<text text-anchor=\"middle\" x=\"868.5\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"868.5\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 48674</text>\n",
       "<text text-anchor=\"middle\" x=\"868.5\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [24337, 24337]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"707.5,-365 597.5,-365 597.5,-297 707.5,-297 707.5,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[6] &lt;= 0.017</text>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.231</text>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13608</text>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1813, 11795]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M810.8997,-407.2665C781.9057,-393.3064 746.6645,-376.3385 716.7908,-361.9548\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"718.2332,-358.7648 707.7048,-357.5801 715.1964,-365.0718 718.2332,-358.7648\"/>\n",
       "<text text-anchor=\"middle\" x=\"715.9635\" y=\"-377.4765\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1151,-365 1036,-365 1036,-297 1151,-297 1151,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[4] &lt;= 0.191</text>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.459</text>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35066</text>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [22524, 12542]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>0&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M926.1509,-408.3525C956.8439,-394.1655 994.7485,-376.6451 1026.7178,-361.8682\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1028.3903,-364.951 1035.999,-357.5782 1025.4532,-358.597 1028.3903,-364.951\"/>\n",
       "<text text-anchor=\"middle\" x=\"1027.3696\" y=\"-377.3417\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"361,-261 262,-261 262,-193 361,-193 361,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[5] &lt;= 0.137</text>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.095</text>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4855</text>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [242, 4613]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M597.3335,-314.175C535.2466,-295.2394 434.7484,-264.589 370.9555,-245.133\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"371.6298,-241.6796 361.0437,-242.1101 369.5877,-248.3751 371.6298,-241.6796\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"705,-261 600,-261 600,-193 705,-193 705,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 0.326</text>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.295</text>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8753</text>\n",
       "<text text-anchor=\"middle\" x=\"652.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1571, 7182]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M652.5,-296.9465C652.5,-288.776 652.5,-279.9318 652.5,-271.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"656.0001,-271.13 652.5,-261.13 649.0001,-271.13 656.0001,-271.13\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"190,-157 91,-157 91,-89 190,-89 190,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[6] &lt;= 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.128</text>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1891</text>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [130, 1761]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261.58,-196.6393C241.9133,-184.6783 219.1897,-170.8581 198.7774,-158.4436\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.549,-155.4246 190.1864,-153.2186 196.9116,-161.4053 200.549,-155.4246\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"361,-157 262,-157 262,-89 361,-89 361,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.073</text>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2964</text>\n",
       "<text text-anchor=\"middle\" x=\"311.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [112, 2852]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M311.5,-192.9465C311.5,-184.776 311.5,-175.9318 311.5,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"315.0001,-167.13 311.5,-157.13 308.0001,-167.13 315.0001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"73,-53 0,-53 0,0 73,0 73,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"36.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.48</text>\n",
       "<text text-anchor=\"middle\" x=\"36.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"36.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3, 2]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103.8335,-88.9777C93.7675,-79.6376 82.8596,-69.5163 72.8135,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.0385,-57.4847 65.3274,-53.2485 70.2772,-62.616 75.0385,-57.4847\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"190,-53 91,-53 91,0 190,0 190,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.126</text>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1886</text>\n",
       "<text text-anchor=\"middle\" x=\"140.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [127, 1759]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.5,-88.9777C140.5,-80.7364 140.5,-71.887 140.5,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"144.0001,-63.2484 140.5,-53.2485 137.0001,-63.2485 144.0001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"302.5,-53 208.5,-53 208.5,0 302.5,0 302.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.068</text>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2759</text>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [97, 2662]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291.7565,-88.9777C286.7083,-80.2786 281.2669,-70.9018 276.1734,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"279.0689,-60.1409 271.0224,-53.2485 273.0145,-63.6544 279.0689,-60.1409\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"410,-53 321,-53 321,0 410,0 410,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.136</text>\n",
       "<text text-anchor=\"middle\" x=\"365.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 205</text>\n",
       "<text text-anchor=\"middle\" x=\"365.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [15, 190]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M330.5384,-88.9777C335.4063,-80.2786 340.6534,-70.9018 345.565,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"348.7029,-63.6843 350.5319,-53.2485 342.5943,-60.2659 348.7029,-63.6843\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"644,-157 545,-157 545,-89 644,-89 644,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.271</text>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5694</text>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [919, 4775]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M633.5086,-192.9465C628.7017,-184.3271 623.4765,-174.9579 618.4591,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"621.4615,-164.1589 613.534,-157.13 615.348,-167.5684 621.4615,-164.1589\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"761,-157 662,-157 662,-89 761,-89 761,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.201</text>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.335</text>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3059</text>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [652, 2407]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>9&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M671.8188,-192.9465C676.7087,-184.3271 682.0239,-174.9579 687.1278,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"690.2476,-167.5549 692.1378,-157.13 684.1592,-164.1008 690.2476,-167.5549\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"527,-53 428,-53 428,0 527,0 527,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"477.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.247</text>\n",
       "<text text-anchor=\"middle\" x=\"477.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3955</text>\n",
       "<text text-anchor=\"middle\" x=\"477.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [571, 3384]</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M553.2502,-88.9777C541.7039,-79.4545 529.1729,-69.1191 517.689,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"519.8724,-56.9113 509.9308,-53.2485 515.4184,-62.3115 519.8724,-56.9113\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"644,-53 545,-53 545,0 644,0 644,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.32</text>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1739</text>\n",
       "<text text-anchor=\"middle\" x=\"594.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [348, 1391]</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M594.5,-88.9777C594.5,-80.7364 594.5,-71.887 594.5,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"598.0001,-63.2484 594.5,-53.2485 591.0001,-63.2485 598.0001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"761,-53 662,-53 662,0 761,0 761,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.364</text>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1558</text>\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [373, 1185]</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M711.5,-88.9777C711.5,-80.7364 711.5,-71.887 711.5,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"715.0001,-63.2484 711.5,-53.2485 708.0001,-63.2485 715.0001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"878,-53 779,-53 779,0 878,0 878,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"828.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.303</text>\n",
       "<text text-anchor=\"middle\" x=\"828.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1501</text>\n",
       "<text text-anchor=\"middle\" x=\"828.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [279, 1222]</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M752.7498,-88.9777C764.2961,-79.4545 776.8271,-69.1191 788.311,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"790.5816,-62.3115 796.0692,-53.2485 786.1276,-56.9113 790.5816,-62.3115\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1146,-261 1041,-261 1041,-193 1146,-193 1146,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.34</text>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.439</text>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4515</text>\n",
       "<text text-anchor=\"middle\" x=\"1093.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1470, 3045]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1093.5,-296.9465C1093.5,-288.776 1093.5,-279.9318 1093.5,-271.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1097.0001,-271.13 1093.5,-261.13 1090.0001,-271.13 1097.0001,-271.13\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1488.5,-261 1378.5,-261 1378.5,-193 1488.5,-193 1488.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[3] &lt;= 0.684</text>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.428</text>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30551</text>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [21054, 9497]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;24 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>16&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1151.1764,-313.3578C1211.4224,-294.9296 1305.7348,-266.0811 1368.5596,-246.8641\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1369.8233,-250.1377 1378.3622,-243.8657 1367.7757,-243.4439 1369.8233,-250.1377\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1081.5,-157 987.5,-157 987.5,-89 1081.5,-89 1081.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"1034.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"1034.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.245</text>\n",
       "<text text-anchor=\"middle\" x=\"1034.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 754</text>\n",
       "<text text-anchor=\"middle\" x=\"1034.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [108, 646]</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1074.1812,-192.9465C1069.2913,-184.3271 1063.9761,-174.9579 1058.8722,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1061.8408,-164.1008 1053.8622,-157.13 1055.7524,-167.5549 1061.8408,-164.1008\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1205,-157 1100,-157 1100,-89 1205,-89 1205,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"1152.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[6] &lt;= 0.008</text>\n",
       "<text text-anchor=\"middle\" x=\"1152.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.462</text>\n",
       "<text text-anchor=\"middle\" x=\"1152.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3761</text>\n",
       "<text text-anchor=\"middle\" x=\"1152.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1362, 2399]</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1112.8188,-192.9465C1117.7087,-184.3271 1123.0239,-174.9579 1128.1278,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1131.2476,-167.5549 1133.1378,-157.13 1125.1592,-164.1008 1131.2476,-167.5549\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"985,-53 896,-53 896,0 985,0 985,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"940.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.235</text>\n",
       "<text text-anchor=\"middle\" x=\"940.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 727</text>\n",
       "<text text-anchor=\"middle\" x=\"940.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [99, 628]</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1001.3591,-88.9777C992.3502,-79.7292 982.5952,-69.7147 973.5891,-60.4691\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"976.0404,-57.9696 966.5555,-53.2485 971.0261,-62.8539 976.0404,-57.9696\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1081.5,-53 1003.5,-53 1003.5,0 1081.5,0 1081.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1042.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n",
       "<text text-anchor=\"middle\" x=\"1042.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 27</text>\n",
       "<text text-anchor=\"middle\" x=\"1042.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [9, 18]</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1037.3205,-88.9777C1038.0113,-80.6449 1038.7537,-71.6903 1039.4545,-63.2364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1042.9443,-63.5035 1040.2825,-53.2485 1035.9682,-62.9251 1042.9443,-63.5035\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1189,-53 1100,-53 1100,0 1189,0 1189,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1144.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.104</text>\n",
       "<text text-anchor=\"middle\" x=\"1144.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 200</text>\n",
       "<text text-anchor=\"middle\" x=\"1144.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 189]</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>21&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1149.6795,-88.9777C1148.9887,-80.6449 1148.2463,-71.6903 1147.5455,-63.2364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1151.0318,-62.9251 1146.7175,-53.2485 1144.0557,-63.5035 1151.0318,-62.9251\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>23</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1312,-53 1207,-53 1207,0 1312,0 1312,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1259.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.471</text>\n",
       "<text text-anchor=\"middle\" x=\"1259.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3561</text>\n",
       "<text text-anchor=\"middle\" x=\"1259.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1351, 2210]</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;23 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>21&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1190.2242,-88.9777C1200.5806,-79.6376 1211.8031,-69.5163 1222.139,-60.1947\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1224.7591,-62.5449 1229.8411,-53.2485 1220.0709,-57.3467 1224.7591,-62.5449\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>25</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1488.5,-157 1378.5,-157 1378.5,-89 1488.5,-89 1488.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[6] &lt;= 0.012</text>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.457</text>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20608</text>\n",
       "<text text-anchor=\"middle\" x=\"1433.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [13309, 7299]</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;25 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>24&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1433.5,-192.9465C1433.5,-184.776 1433.5,-175.9318 1433.5,-167.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1437.0001,-167.13 1433.5,-157.13 1430.0001,-167.13 1437.0001,-167.13\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>28</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1671,-157 1566,-157 1566,-89 1671,-89 1671,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2] &lt;= 0.93</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.344</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9943</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [7745, 2198]</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;28 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>24&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1488.5052,-196.0782C1510.036,-183.9744 1534.8292,-170.0365 1556.9524,-157.5997\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1558.9273,-160.5047 1565.9291,-152.5533 1555.497,-154.4028 1558.9273,-160.5047\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1419,-53 1330,-53 1330,0 1419,0 1419,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1374.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.348</text>\n",
       "<text text-anchor=\"middle\" x=\"1374.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 357</text>\n",
       "<text text-anchor=\"middle\" x=\"1374.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [80, 277]</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;26 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>25&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1412.6988,-88.9777C1407.3242,-80.187 1401.5265,-70.7044 1396.1115,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1399.0564,-59.9545 1390.854,-53.2485 1393.0842,-63.6059 1399.0564,-59.9545\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1547.5,-53 1437.5,-53 1437.5,0 1547.5,0 1547.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1492.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.453</text>\n",
       "<text text-anchor=\"middle\" x=\"1492.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20251</text>\n",
       "<text text-anchor=\"middle\" x=\"1492.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [13229, 7022]</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;27 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>25&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1454.3012,-88.9777C1459.6758,-80.187 1465.4735,-70.7044 1470.8885,-61.8477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1473.9158,-63.6059 1476.146,-53.2485 1467.9436,-59.9545 1473.9158,-63.6059\"/>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1671,-53 1566,-53 1566,0 1671,0 1671,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.315</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6152</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4948, 1204]</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;29 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>28&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1618.5,-88.9777C1618.5,-80.7364 1618.5,-71.887 1618.5,-63.5153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1622.0001,-63.2484 1618.5,-53.2485 1615.0001,-63.2485 1622.0001,-63.2484\"/>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"1788,-53 1689,-53 1689,0 1788,0 1788,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"1738.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.387</text>\n",
       "<text text-anchor=\"middle\" x=\"1738.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3791</text>\n",
       "<text text-anchor=\"middle\" x=\"1738.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2797, 994]</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;30 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>28&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1660.8075,-88.9777C1672.6499,-79.4545 1685.5021,-69.1191 1697.2805,-59.6473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1699.6382,-62.2427 1705.2376,-53.2485 1695.2514,-56.7877 1699.6382,-62.2427\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a1e6f89b0>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data=tree.export_graphviz(clf_cart, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf_cart,out_file='tree.dot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.736\n",
      "accuracy score of test set: 0.846\n",
      "auc score of test set: 0.745\n",
      "recall score of test set: 0.615\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     10967\n",
      "        1.0       0.38      0.61      0.47      1386\n",
      "\n",
      "avg / total       0.88      0.85      0.86     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_cart.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_cart.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_cart.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.736\n",
      "accuracy score of test set: 0.844\n",
      "auc score of test set: 0.738\n",
      "recall score of test set: 0.601\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.87      0.91      7314\n",
      "        1.0       0.38      0.60      0.46       922\n",
      "\n",
      "avg / total       0.88      0.84      0.86      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_cart.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_cart.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_cart.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#huge tree; very messy\n",
    "#import graphviz\n",
    "#dot_data=tree.export_graphviz(clf_cart, out_file=None)\n",
    "#graph = graphviz.Source(dot_data)\n",
    "#graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>RF</font>\n",
    "<font color='black'>Model Ensemble - Bagging (Average)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/titanic/discussion/10089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.744\n",
      "accuracy score of test set: 0.845\n",
      "auc score of test set: 0.729\n",
      "recall score of test set: 0.578\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91     12178\n",
      "        1.0       0.38      0.58      0.46      1548\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.744\n",
      "accuracy score of test set: 0.845\n",
      "auc score of test set: 0.732\n",
      "recall score of test set: 0.588\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91     12199\n",
      "        1.0       0.37      0.59      0.46      1526\n",
      "\n",
      "avg / total       0.88      0.84      0.86     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.742\n",
      "accuracy score of test set: 0.848\n",
      "auc score of test set: 0.735\n",
      "recall score of test set: 0.589\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91     12160\n",
      "        1.0       0.39      0.59      0.47      1565\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.744, 0.001\n",
      "Test set accuracy for all folds, Mean & Std: 0.846, 0.002\n",
      "Test set auc for all folds, Mean & Std: 0.732, 0.003\n",
      "Test set recall for all folds, Mean & Std: 0.585, 0.005\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_rf.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = clf_rf.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = clf_rf.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.739\n",
      "accuracy score of test set: 0.847\n",
      "auc score of test set: 0.741\n",
      "recall score of test set: 0.605\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     10967\n",
      "        1.0       0.38      0.61      0.47      1386\n",
      "\n",
      "avg / total       0.88      0.85      0.86     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_rf.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_rf.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_rf.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.743\n",
      "accuracy score of test set: 0.844\n",
      "auc score of test set: 0.735\n",
      "recall score of test set: 0.594\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91      7314\n",
      "        1.0       0.38      0.59      0.46       922\n",
      "\n",
      "avg / total       0.88      0.84      0.86      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_rf.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_rf.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_rf.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.116, 0.426, 3.978, 0.338, 1.706, 2.139, 1.297])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((clf_rf.feature_importances_)*10,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explanation between the different types of Naive Bayes methods: Gaussian, Multinomial, Bernoulli:\n",
    "#https://blog.sicara.com/naive-bayes-classifier-sklearn-python-example-tips-42d100429e44\n",
    "\n",
    "#Code to implement for Naive Bayes:\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.691\n",
      "accuracy score of test set: 0.875\n",
      "auc score of test set: 0.682\n",
      "recall score of test set: 0.434\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93     12216\n",
      "        1.0       0.43      0.43      0.43      1510\n",
      "\n",
      "avg / total       0.88      0.88      0.88     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.683\n",
      "accuracy score of test set: 0.877\n",
      "auc score of test set: 0.701\n",
      "recall score of test set: 0.473\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93     12155\n",
      "        1.0       0.46      0.47      0.47      1570\n",
      "\n",
      "avg / total       0.88      0.88      0.88     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.69\n",
      "accuracy score of test set: 0.874\n",
      "auc score of test set: 0.685\n",
      "recall score of test set: 0.439\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93     12166\n",
      "        1.0       0.45      0.44      0.44      1559\n",
      "\n",
      "avg / total       0.87      0.87      0.87     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.688, 0.003\n",
      "Test set accuracy for all folds, Mean & Std: 0.876, 0.001\n",
      "Test set auc for all folds, Mean & Std: 0.689, 0.008\n",
      "Test set recall for all folds, Mean & Std: 0.449, 0.017\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    gnb.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = gnb.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = gnb.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.677\n",
      "accuracy score of test set: 0.84\n",
      "auc score of test set: 0.683\n",
      "recall score of test set: 0.481\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.89      0.91     10967\n",
      "        1.0       0.35      0.48      0.40      1386\n",
      "\n",
      "avg / total       0.87      0.84      0.85     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "gnb.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = gnb.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = gnb.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.688\n",
      "accuracy score of test set: 0.877\n",
      "auc score of test set: 0.694\n",
      "recall score of test set: 0.46\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.93      0.93      7314\n",
      "        1.0       0.45      0.46      0.45       922\n",
      "\n",
      "avg / total       0.88      0.88      0.88      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "gnb.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = gnb.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = gnb.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>NN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_nn=MLPClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.737\n",
      "accuracy score of test set: 0.848\n",
      "auc score of test set: 0.74\n",
      "recall score of test set: 0.601\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     12209\n",
      "        1.0       0.38      0.60      0.47      1517\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.741\n",
      "accuracy score of test set: 0.841\n",
      "auc score of test set: 0.731\n",
      "recall score of test set: 0.589\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.87      0.91     12198\n",
      "        1.0       0.37      0.59      0.45      1527\n",
      "\n",
      "avg / total       0.88      0.84      0.86     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.725\n",
      "accuracy score of test set: 0.769\n",
      "auc score of test set: 0.727\n",
      "recall score of test set: 0.673\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.86     12130\n",
      "        1.0       0.29      0.67      0.40      1595\n",
      "\n",
      "avg / total       0.87      0.77      0.80     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.735, 0.007\n",
      "Test set accuracy for all folds, Mean & Std: 0.819, 0.036\n",
      "Test set auc for all folds, Mean & Std: 0.733, 0.005\n",
      "Test set recall for all folds, Mean & Std: 0.621, 0.037\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_nn.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = clf_nn.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = clf_nn.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.734\n",
      "accuracy score of test set: 0.846\n",
      "auc score of test set: 0.745\n",
      "recall score of test set: 0.615\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     10967\n",
      "        1.0       0.38      0.61      0.47      1386\n",
      "\n",
      "avg / total       0.88      0.85      0.86     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_nn.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_nn.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_nn.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.738\n",
      "accuracy score of test set: 0.843\n",
      "auc score of test set: 0.738\n",
      "recall score of test set: 0.602\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.87      0.91      7314\n",
      "        1.0       0.37      0.60      0.46       922\n",
      "\n",
      "avg / total       0.88      0.84      0.86      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_nn.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_nn.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_nn.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>AdaBoost</font>\n",
    "<font color='black'>Model Ensemble - Boosting (Weighted Average)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/ensemble.html#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ada = AdaBoostClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.745\n",
      "accuracy score of test set: 0.834\n",
      "auc score of test set: 0.735\n",
      "recall score of test set: 0.608\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.86      0.90     12190\n",
      "        1.0       0.36      0.61      0.45      1536\n",
      "\n",
      "avg / total       0.88      0.83      0.85     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.744\n",
      "accuracy score of test set: 0.844\n",
      "auc score of test set: 0.734\n",
      "recall score of test set: 0.592\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91     12182\n",
      "        1.0       0.38      0.59      0.46      1543\n",
      "\n",
      "avg / total       0.88      0.84      0.86     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.733\n",
      "accuracy score of test set: 0.836\n",
      "auc score of test set: 0.752\n",
      "recall score of test set: 0.644\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.86      0.90     12165\n",
      "        1.0       0.37      0.64      0.47      1560\n",
      "\n",
      "avg / total       0.88      0.84      0.85     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.741, 0.006\n",
      "Test set accuracy for all folds, Mean & Std: 0.838, 0.004\n",
      "Test set auc for all folds, Mean & Std: 0.74, 0.008\n",
      "Test set recall for all folds, Mean & Std: 0.614, 0.022\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_ada.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = clf_ada.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = clf_ada.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.738\n",
      "accuracy score of test set: 0.835\n",
      "auc score of test set: 0.747\n",
      "recall score of test set: 0.633\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.86      0.90     10967\n",
      "        1.0       0.36      0.63      0.46      1386\n",
      "\n",
      "avg / total       0.88      0.83      0.85     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_ada.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_ada.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_ada.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.736\n",
      "accuracy score of test set: 0.832\n",
      "auc score of test set: 0.735\n",
      "recall score of test set: 0.611\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.86      0.90      7314\n",
      "        1.0       0.36      0.61      0.45       922\n",
      "\n",
      "avg / total       0.88      0.83      0.85      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_ada.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_ada.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_ada.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Gradient Boost</font>\n",
    "<font color='black'>Model Ensemble - Boosting (Weighted Average) + Fastest descent route</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/ensemble.html#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_gb = GradientBoostingClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.737\n",
      "accuracy score of test set: 0.845\n",
      "auc score of test set: 0.747\n",
      "recall score of test set: 0.621\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.87      0.91     12174\n",
      "        1.0       0.38      0.62      0.48      1552\n",
      "\n",
      "avg / total       0.88      0.84      0.86     13726\n",
      "\n",
      " \n",
      "Fold 2:\n",
      "accuracy score of training set: 0.74\n",
      "accuracy score of test set: 0.849\n",
      "auc score of test set: 0.743\n",
      "recall score of test set: 0.606\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     12159\n",
      "        1.0       0.40      0.61      0.48      1566\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.75\n",
      "accuracy score of test set: 0.845\n",
      "auc score of test set: 0.73\n",
      "recall score of test set: 0.582\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.88      0.91     12204\n",
      "        1.0       0.37      0.58      0.45      1521\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.742, 0.006\n",
      "Test set accuracy for all folds, Mean & Std: 0.846, 0.002\n",
      "Test set auc for all folds, Mean & Std: 0.74, 0.007\n",
      "Test set recall for all folds, Mean & Std: 0.603, 0.016\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    clf_gb.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = clf_gb.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = clf_gb.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.741\n",
      "accuracy score of test set: 0.847\n",
      "auc score of test set: 0.748\n",
      "recall score of test set: 0.621\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     10967\n",
      "        1.0       0.39      0.62      0.48      1386\n",
      "\n",
      "avg / total       0.89      0.85      0.86     12353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_gb.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_gb.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_gb.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.741\n",
      "accuracy score of test set: 0.844\n",
      "auc score of test set: 0.741\n",
      "recall score of test set: 0.608\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.87      0.91      7314\n",
      "        1.0       0.38      0.61      0.47       922\n",
      "\n",
      "avg / total       0.88      0.84      0.86      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf_gb.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = clf_gb.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = clf_gb.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>XG Boost</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computationally expensive (time consuming) to do cv on XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "accuracy score of training set: 0.741\n",
      "accuracy score of test set: 0.849\n",
      "auc score of test set: 0.742\n",
      "recall score of test set: 0.603\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     12183\n",
      "        1.0       0.39      0.60      0.47      1543\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13726\n",
      "\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "accuracy score of training set: 0.745\n",
      "accuracy score of test set: 0.848\n",
      "auc score of test set: 0.738\n",
      "recall score of test set: 0.598\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.88      0.91     12225\n",
      "        1.0       0.38      0.60      0.46      1500\n",
      "\n",
      "avg / total       0.88      0.85      0.86     13725\n",
      "\n",
      " \n",
      "Fold 3:\n",
      "accuracy score of training set: 0.741\n",
      "accuracy score of test set: 0.843\n",
      "auc score of test set: 0.741\n",
      "recall score of test set: 0.607\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.87      0.91     12129\n",
      "        1.0       0.39      0.61      0.47      1596\n",
      "\n",
      "avg / total       0.88      0.84      0.86     13725\n",
      "\n",
      " \n",
      "Overall:\n",
      "Training set accuracy for all folds, Mean & Std: 0.742, 0.002\n",
      "Test set accuracy for all folds, Mean & Std: 0.847, 0.003\n",
      "Test set auc for all folds, Mean & Std: 0.74, 0.001\n",
      "Test set recall for all folds, Mean & Std: 0.603, 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "Fold = 0\n",
    "accuracy_values_train=[]\n",
    "accuracy_values_test=[]\n",
    "auc_values_test=[]\n",
    "recall_values_test=[]\n",
    "\n",
    "kf = model_selection.KFold(n_splits=3, shuffle=True)\n",
    "for train_index, test_index in kf.split(clients_all_norm):\n",
    "\n",
    "    X_train, X_test = X_Matrix.iloc[train_index], X_Matrix.iloc[test_index]\n",
    "    y_train, y_test = y_series.iloc[train_index], y_series.iloc[test_index]\n",
    "    \n",
    "    X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "    \n",
    "    X_train_resampled = pd.DataFrame(X_train_resampled, columns = X_train.columns)\n",
    "    y_train_resampled = (pd.Series(y_train_resampled)).rename('y_coded')\n",
    "    \n",
    "    xgb.fit(X_train_resampled,y_train_resampled)\n",
    "    pred_train = xgb.predict(X_train_resampled)\n",
    "    true_train = y_train_resampled\n",
    "    pred = xgb.predict(X_test)\n",
    "    true = y_test\n",
    "    \n",
    "    Fold+=1\n",
    "    print(\"Fold \"+ str(Fold) + \":\")\n",
    "    print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "    print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "    print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "    print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "    print(\"classification report of test set: \")\n",
    "    print(classification_report(true, pred))\n",
    "    print(\" \")\n",
    "    \n",
    "    accuracy_values_train.append(metrics.accuracy_score(true_train,pred_train))\n",
    "    accuracy_values_test.append(metrics.accuracy_score(true,pred))\n",
    "    auc_values_test.append(metrics.roc_auc_score(true,pred))\n",
    "    recall_values_test.append(metrics.recall_score(true,pred))\n",
    "    \n",
    "print(\"Overall:\")\n",
    "print(\"Training set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_train).round(decimals=3))+ \", \" + str(np.std(accuracy_values_train).round(decimals=3)))          \n",
    "print(\"Test set accuracy for all folds, Mean & Std: \" +str(np.mean(accuracy_values_test).round(decimals=3))+ \", \" + str(np.std(accuracy_values_test).round(decimals=3)))\n",
    "print(\"Test set auc for all folds, Mean & Std: \" + str(np.mean(auc_values_test).round(decimals=3)) + \", \" + str(np.std(auc_values_test).round(decimals=3)))\n",
    "print(\"Test set recall for all folds, Mean & Std: \" + str(np.mean(recall_values_test).round(decimals=3))+ \", \" + str(np.std(recall_values_test).round(decimals=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.739\n",
      "accuracy score of test set: 0.847\n",
      "auc score of test set: 0.749\n",
      "recall score of test set: 0.623\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.87      0.91     10967\n",
      "        1.0       0.39      0.62      0.48      1386\n",
      "\n",
      "avg / total       0.89      0.85      0.86     12353\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.3, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train_resampled = pd.DataFrame(X_train_resampled, columns = X_train.columns)\n",
    "y_train_resampled = (pd.Series(y_train_resampled)).rename('y_coded')\n",
    "\n",
    "xgb.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = xgb.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = xgb.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of training set: 0.741\n",
      "accuracy score of test set: 0.844\n",
      "auc score of test set: 0.742\n",
      "recall score of test set: 0.611\n",
      "classification report of test set: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.87      0.91      7314\n",
      "        1.0       0.38      0.61      0.47       922\n",
      "\n",
      "avg / total       0.88      0.84      0.86      8236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/tanhongyue/anaconda2/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Matrix, y_series, test_size=0.2, random_state=1)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train_resampled = pd.DataFrame(X_train_resampled, columns = X_train.columns)\n",
    "y_train_resampled = (pd.Series(y_train_resampled)).rename('y_coded')\n",
    "\n",
    "xgb.fit(X_train_resampled,y_train_resampled)\n",
    "pred_train = xgb.predict(X_train_resampled)\n",
    "true_train = y_train_resampled\n",
    "pred = xgb.predict(X_test)\n",
    "true = y_test\n",
    "\n",
    "print(\"accuracy score of training set: \" + str(metrics.accuracy_score(true_train,pred_train).round(decimals=3)))\n",
    "print(\"accuracy score of test set: \" + str(metrics.accuracy_score(true,pred).round(decimals=3)))\n",
    "print(\"auc score of test set: \" + str(metrics.roc_auc_score(true,pred).round(decimals=3)))\n",
    "print(\"recall score of test set: \" + str(metrics.recall_score(true,pred).round(decimals=3)))\n",
    "print(\"classification report of test set: \")\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 4: Rebalancing using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 5: Rebalancing using Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch\n",
    "#feature selection\n",
    "#clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
